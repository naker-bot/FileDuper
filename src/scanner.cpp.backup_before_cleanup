#include "scanner.h"
#include "hashengine.h"
#include "presetmanager.h"
#include "ftpclient.h"
#include <QDebug>
#include <QDir>
#include <QDirIterator>
#include <QDateTime>
#include <QCryptographicHash>
#include <QFileInfo>
#include <QUrl>
#include <QApplication>
#include <QThreadPool>
#include <QFutureWatcher>
#include <QtConcurrent/QtConcurrent>
#include <QMutex>
#include <QEventLoop>
#include <QTimer>
#include <QThread>
#include <iostream>
#include <vector>
#include <curl/curl.h>

// üõ°Ô∏è HELPER: URL-sichere Pfad-Normalisierung (FTP-kompatibel)
QString Scanner::getCanonicalPath(const QString &filePath) {
    if (filePath.startsWith("ftp://") || filePath.startsWith("sftp://") || filePath.startsWith("smb://")) {
        // Network URLs: verwende URL-basierte Normalisierung
        return QUrl(filePath).toString();
    } else {
        // Local files: verwende QFileInfo
        return QFileInfo(filePath).canonicalFilePath();
    }
}

// üõ°Ô∏è HELPER: URL-sicherer Dateiname-Extraktor (FTP-kompatibel)
QString Scanner::extractFileName(const QString &filePath) {
    if (filePath.startsWith("ftp://") || filePath.startsWith("sftp://") || filePath.startsWith("smb://")) {
        // Network URLs: extrahiere Dateiname vom URL-Ende
        QUrl url(filePath);
        QString path = url.path();
        return path.split('/').last();
    } else {
        // Local files: verwende QFileInfo
        return QFileInfo(filePath).fileName();
    }
}

Scanner::Scanner(QObject *parent)
    : QObject(parent), hashEngine(nullptr), presetManager(nullptr), ftpClient(nullptr),
      scanning(false), paused(false), currentPhase(IDLE), ftpDirectoriesProcessed(0),
      threadPool(nullptr), futureWatcher(nullptr),
      currentFileIndex(0), activeEngines(0), processedFiles(0), completedEngines(0),
      maxConnectionsPerHost(2)  // ‚úÖ POOL ENGINE + MULTI-HOST FTP INIT
{
    std::cout << "[Scanner] üîç Scanner initialisiert" << std::endl;

    // üöÄ SAFE-SPEED: Kontrolliertes Threading Setup
    threadPool = QThreadPool::globalInstance();
    
    // üßµ SAFE THREADING: Begrenzt auf max 8 Threads f√ºr Stabilit√§t
    int coreCount = QThread::idealThreadCount();
    
    // üõ°Ô∏è DIVISION BY ZERO PROTECTION: Fallback wenn idealThreadCount() == 0
    if (coreCount <= 0) {
        coreCount = 4; // Fallback auf 4 Kerne wenn Hardware-Erkennung fehlschl√§gt
        qWarning() << "[Scanner] ‚ö†Ô∏è DIVISION-BY-ZERO verhindert: idealThreadCount()=0, verwende Fallback=4";
    }
    
    
    // üéØ SAFE Thread Scaling - BEGRENZT auf max 8 Threads f√ºr Stabilit√§t
    int maxThreads = qMin(8, coreCount * 2);  // Nie mehr als 8 Threads
    
    threadPool->setMaxThreadCount(maxThreads);
    std::cout << "[Scanner] üöÄ SAFE-SPEED aktiviert: " << maxThreads << " Threads (" << coreCount << " Kerne √ó 2, begrenzt auf 8) - STABLE MODE" << std::endl;
    
    futureWatcher = new QFutureWatcher<void>(this);
    connect(futureWatcher, &QFutureWatcher<void>::finished, this, &Scanner::onCollectionFinished);

    // üöÄ SAFE-SPEED: Stabiler Processing Timer
    processTimer = new QTimer(this);
    processTimer->setSingleShot(false);
    processTimer->setInterval(10); // üöÄ SAFE: 10ms f√ºr stabile Performance
    connect(processTimer, &QTimer::timeout, this, &Scanner::processNextFile);

    // Initialisiere Pfad-Deduplicator f√ºr optimierte Verarbeitung
}

Scanner::~Scanner()
{
    stopScan();
}

void Scanner::setHashEngine(HashEngine *engine)
{
    hashEngine = engine;
    if (hashEngine)
    {
        // ‚õî CRITICAL: Set Scanner as parent so HashEngine can call stopAllEngines
        hashEngine->setParent(this);
        
        // ‚õî CRITICAL: Connect login failure signal to stopAllEngines
        connect(hashEngine, &HashEngine::loginFailed, this, &Scanner::stopAllEngines, Qt::QueuedConnection);
        std::cout << "[Scanner] ‚úÖ HashEngine Parent gesetzt + loginFailed Signal verbunden" << std::endl;
        
        connect(hashEngine, &HashEngine::hashCalculated,
                this, &Scanner::onHashCalculated);
    }
}

void Scanner::setPresetManager(PresetManager *manager)
{
    presetManager = manager;
}

void Scanner::setFtpClient(FtpClient *client)
{
    ftpClient = client;
    if (ftpClient)
    {
        connect(ftpClient, &FtpClient::listFinished,
                this, &Scanner::onFtpListFinished);
    }
}

void Scanner::startScan(const QStringList &directories, const QString &hashAlgorithm, const QString &fileFilter)
{
    qDebug() << "[Scanner] üöÄ startScan aufgerufen mit" << directories.size() << "Verzeichnissen:" << directories;
    qDebug() << "[Scanner] Hash-Algorithmus:" << hashAlgorithm << "FileFilter:" << fileFilter;

    // üõ°Ô∏è SAFETY CHECK: Vermeide Null-Pointer-Zugriffe
    if (!processTimer) {
        qDebug() << "[Scanner] ‚ùå FATAL: processTimer ist null - Scanner nicht korrekt initialisiert!";
        emit error("Scanner not properly initialized - processTimer is null");
        return;
    }
    
    if (!threadPool) {
        qDebug() << "[Scanner] ‚ùå FATAL: threadPool ist null - Scanner nicht korrekt initialisiert!";
        emit error("Scanner not properly initialized - threadPool is null");
        return;
    }

    // ‚úÖ FIX: Pr√ºfe ob bereits ein Scan l√§uft
    if (scanning.load()) {
        qDebug() << "[Scanner] ‚è∏Ô∏è Stoppe vorherigen Scan, starte neuen...";
        stopScan(); // Stoppe aktuellen Scan
        scanning.store(false); // Reset scanning state
    }

    if (directories.isEmpty()) {
        qDebug() << "[Scanner] ‚ùå Keine Verzeichnisse zum Scannen!";
        emit scanCompleted(DuplicateGroups{});
        return;
    }

    // ‚úÖ NEU: Separiere lokale und FTP-Pfade f√ºr parallele Verarbeitung
    QStringList localDirectories;
    QStringList ftpDirectories;
    
    for (const QString &dir : directories) {
        if (dir.startsWith("ftp://") || dir.startsWith("sftp://") || dir.startsWith("smb://")) {
            ftpDirectories.append(dir);
        } else {
            localDirectories.append(dir);
        }
    }
    
    qDebug() << "[Scanner] üìÇ Lokale Verzeichnisse:" << localDirectories.size();
    qDebug() << "[Scanner] üì° Netzwerk-Verzeichnisse:" << ftpDirectories.size();

    // Deduplicate directories to prevent redundant work
    QStringList optimizedDirectories = deduplicateDirectories(directories);
    
    if (optimizedDirectories.isEmpty()) {
        qDebug() << "[Scanner] ‚ùå Nach Pfad-Optimierung keine Verzeichnisse √ºbrig!";
        emit scanCompleted(DuplicateGroups{});
        return;
    }

    scanDirectories = optimizedDirectories;
    currentHashAlgorithm = hashAlgorithm;
    currentFileFilter = fileFilter;

    // üõ°Ô∏è SAFETY CHECK: HashEngine muss gesetzt sein
    if (!hashEngine) {
        qDebug() << "[Scanner] ‚ùå FATAL: HashEngine ist null - Scanner kann nicht funktionieren!";
        emit error("Scanner missing HashEngine - cannot calculate hashes");
        scanning.store(false);
        return;
    }

    // üõ°Ô∏è KRITISCH: Deduplication-Caches f√ºr NEUEN Scan zur√ºcksetzen
    clearDeduplicationCaches();
    qDebug() << "[Scanner] üîÑ Neuer Scan gestartet - Deduplication-Caches zur√ºckgesetzt";

    // Reset state
    allFiles.clear();
    fileSizeGroups.clear();
    hashGroups.clear();

    scanning.store(true);
    paused.store(false);
    currentPhase = COLLECTING;

    qDebug() << "[Scanner] üîç Pfad-Optimierung:" << directories.size()
              << "‚Üí" << optimizedDirectories.size() << "Verzeichnisse";
    emit scanStatusChanged("üöÄüöÄüöÄ LUDICROUS-SPEED: OVERKILL-Parallelisierung aktiviert...");

    collectFilesMultithreaded(); // üöÄüöÄüöÄ LUDICROUS: Force Multithreading!
}

QStringList Scanner::deduplicateDirectories(const QStringList &directories)
{
    qDebug() << "[Scanner] üîç deduplicateDirectories gestartet mit" << directories.size() << "Verzeichnissen";
    
    // ‚úÖ TIMEOUT-SCHUTZ: Verhindere H√§ngen bei komplexer Pfad-Deduplication
    QElapsedTimer deduplicationTimer;
    deduplicationTimer.start();
    const qint64 MAX_DEDUPLICATION_TIME_MS = 30000; // 30 Sekunden Maximum
    
    QSet<QString> canonicalPaths;
    QStringList result;

    // Convert all paths to canonical form (handle both local and FTP paths)
    QMap<QString, QString> originalToCanonical;
    for (const QString &dir : directories)
    {
        // ‚úÖ TIMEOUT-CHECK: Verhindere H√§ngen in Pfad-Konvertierung
        if (deduplicationTimer.elapsed() > MAX_DEDUPLICATION_TIME_MS) {
            qWarning() << "[Scanner] ‚è∞ Timeout bei Pfad-Deduplication nach" 
                      << (deduplicationTimer.elapsed() / 1000) << "Sekunden";
            // Verwende urspr√ºngliche Pfade ohne Deduplication
            return directories;
        }
        
        QString canonical;
        
        // ‚úÖ KORREKTUR: FTP-Pfade beibehalten, nur lokale Pfade kanonisch machen
        if (dir.startsWith("ftp://") || dir.startsWith("sftp://") || dir.startsWith("smb://")) {
            canonical = dir; // FTP/Network paths bleiben unver√§ndert
            qDebug() << "[Scanner] üì° Netzwerk-Pfad beibehalten:" << dir;
        } else {
            canonical = QDir(dir).canonicalPath(); // Nur lokale Pfade kanonisch machen
            qDebug() << "[Scanner] üìÇ Lokaler Pfad:" << dir << "‚Üí" << canonical;
        }
        
        if (!canonical.isEmpty())
        {
            originalToCanonical[dir] = canonical;
        } else {
            qWarning() << "[Scanner] ‚ö†Ô∏è Konnte Pfad nicht aufl√∂sen:" << dir;
        }
    }

    // Remove parent-child relationships and duplicates with timeout protection
    qDebug() << "[Scanner] üîÑ Entferne parent-child Beziehungen aus" << originalToCanonical.size() << "Pfaden";
    
    int processedPaths = 0;
    for (auto it = originalToCanonical.begin(); it != originalToCanonical.end(); ++it)
    {
        // ‚úÖ TIMEOUT-CHECK: Verhindere H√§ngen in Pfad-Analyse
        if (deduplicationTimer.elapsed() > MAX_DEDUPLICATION_TIME_MS) {
            qWarning() << "[Scanner] ‚è∞ Timeout bei Pfad-Analyse - verwende bisherige Ergebnisse";
            break;
        }
        
        QString currentPath = it.value();
        bool isRedundant = false;
        processedPaths++;

        // Progress-Update alle 10 Pfade
        if (processedPaths % 10 == 0) {
            qDebug() << "[Scanner] üìä Pfad-Analyse Progress:" << processedPaths 
                    << "/" << originalToCanonical.size() << "(" 
                    << (deduplicationTimer.elapsed() / 1000) << "s)";
        }

        // Check if this path is a child of any already processed path
        for (const QString &existingPath : canonicalPaths)
        {
            if (currentPath.startsWith(existingPath + "/"))
            {
                isRedundant = true;
                qDebug() << "[Scanner] ‚è≠Ô∏è √úberspringe Unterverzeichnis:" << it.key()
                          << "(enthalten in" << existingPath << ")";
                break;
            }
        }

        if (!isRedundant)
        {
            // Remove any existing paths that are children of the current path
            auto existing = canonicalPaths.begin();
            while (existing != canonicalPaths.end())
            {
                if (existing->startsWith(currentPath + "/"))
                {
                    qDebug() << "[Scanner] üîÑ Ersetze Unterverzeichnis" << *existing
                             << "durch Elternverzeichnis" << currentPath;
                    existing = canonicalPaths.erase(existing);
                }
                else
                {
                    ++existing;
                }
            }

            canonicalPaths.insert(currentPath);
            result.append(it.key());
        }
    }

    return result;
}
void Scanner::stopScan()
{
    if (!scanning.load())
        return;

    qDebug() << "[Scanner] ‚èπÔ∏è FORCE-STOP: Stoppe alle Scan-Aktivit√§ten";
    
    scanning.store(false);
    paused.store(false);
    currentPhase = IDLE;
    
    // ‚úÖ KRITISCH: Stoppe alle Timer
    if (processTimer) {
        processTimer->stop();
        qDebug() << "[Scanner] üõë ProcessTimer gestoppt";
    }
    
    // ‚úÖ KRITISCH: Stoppe HashEngine
    if (hashEngine) {
        // Hier k√∂nnten wir hashEngine->stopCalculation() aufrufen
        qDebug() << "[Scanner] üõë HashEngine-Stop signalisiert";
    }
    
    // ‚úÖ KRITISCH: Leere alle Collections f√ºr sauberen Stop
    allFiles.clear();
    hashGroups.clear();
    fileSizeGroups.clear();
    
    // üõ°Ô∏è NEU: Deduplication-Caches leeren bei Scan-Stop
    globalProcessedFiles.clear();
    globalHashedFiles.clear();
    
    qDebug() << "[Scanner] üßπ Alle Collections geleert";
    qDebug() << "[Scanner] üõ°Ô∏è Deduplication-Caches geleert";
    
    emit scanStatusChanged("‚èπÔ∏è Scan gestoppt - alle Prozesse beendet");
    std::cout << "‚èπÔ∏è Duplikat-Scan vollst√§ndig gestoppt" << std::endl;
    
    // ‚úÖ KRITISCH: Emittiere leere Ergebnisse um GUI zu clearen
    DuplicateGroups emptyResults;
    emit scanCompleted(emptyResults);
}

void Scanner::pauseScan()
{
    if (!scanning.load())
        return;

    paused.store(true);
    processTimer->stop();
    emit scanStatusChanged("Scan pausiert");
    std::cout << "‚è∏Ô∏è Duplikat-Scan pausiert" << std::endl;
}

void Scanner::resumeScan()
{
    if (!scanning.load() || !paused.load())
        return;

    paused.store(false);
    processTimer->start();
    emit scanStatusChanged("Scan fortgesetzt");
    std::cout << "‚ñ∂Ô∏è Duplikat-Scan fortgesetzt" << std::endl;
}

void Scanner::collectFiles()
{
    emit scanStatusChanged("üöÄ Sammle Dateien mit HYPERTHREADING (lokal + netzwerk)...");
    QSet<QString> processedFiles; // Prevent duplicate file processing
    
    // Clear FTP processing state
    pendingFtpDirectories.clear();
    completedFtpDirectories.clear();
    ftpDirectoriesProcessed = 0;
    
    bool hasFtpDirectories = false;
    bool hasLocalDirectories = false;
    
    // ÔøΩ HYPERSPEED: Maximale Batch-Gr√∂√üe f√ºr EXTREME Performance
    const int BATCH_SIZE = 100000;  // ‚ö° 50000 ‚Üí 100000 f√ºr ULTRA-HYPERSPEED lokale Sammlung
    QList<FileInfo> currentBatch;
    int totalFilesProcessed = 0;
    int batchNumber = 1;

    for (const QString &directory : scanDirectories)
    {
        if (!scanning.load())
            return;

        // Check if this is an FTP path
        if (directory.startsWith("ftp://"))
        {
            hasFtpDirectories = true;
            collectFtpFiles(directory, processedFiles);
        }
        else
        {
            hasLocalDirectories = true;
            // üî• HYPERSPEED: Ultra-maximale lokale Dateisammlung
            qDebug() << "[Scanner] üî• HYPERSPEED lokale Sammlung f√ºr:" << directory;
            
            // üéØ OPTIMIERTE LOKALE DATEISAMMLUNG mit Batch-Processing
            QDirIterator it(directory, QDir::Files | QDir::Readable, QDirIterator::Subdirectories);
            
            while (it.hasNext())
            {
                if (!scanning.load())
                    return;

                QString filePath = it.next();
                
                // ‚úÖ EMIT CURRENT FILE PROCESSING f√ºr Real-time UI Update
                QFileInfo tempInfo(filePath);
                emit currentFileProcessing(tempInfo.fileName(), "Collecting", totalFilesProcessed + 1, 0);
                
                QFileInfo fileInfo(filePath);

                // ÔøΩ SCHNELLE PFAD-NORMALISIERUNG
                QString canonicalPath = fileInfo.canonicalFilePath();
                if (canonicalPath.isEmpty()) {
                    canonicalPath = fileInfo.absoluteFilePath();
                }
                
                // üõ°Ô∏è DEDUPLIZIERUNG
                if (processedFiles.contains(canonicalPath))
                {
                    continue; // Skip duplicate files (silent f√ºr Performance)
                }
                processedFiles.insert(canonicalPath);
                
                // ÔøΩ ULTRA-HYPERSPEED: Nur alle 100000 Dateien Debug (f√ºr maximale Speed)
                if (totalFilesProcessed % 100000 == 0) {
                    qDebug() << "[Scanner] üî• HYPERSPEED:" << totalFilesProcessed << "Dateien verarbeitet";
                }
                processedFiles.insert(canonicalPath);

                // üîç SCHNELLE FILTER-PR√úFUNG
                if (!currentFileFilter.isEmpty() && currentFileFilter != "Alle Dateien" && currentFileFilter != "*")
                {
                    QString extension = fileInfo.suffix().toLower();
                    if (!currentFileFilter.contains(extension, Qt::CaseInsensitive))
                    {
                        continue; // Skip filtered files (silent f√ºr Performance)
                    }
                }

                // üö´ SYSTEM-PFAD-AUSSCHLUSS
                if (presetManager && presetManager->shouldExcludePath(filePath))
                {
                    continue; // Skip excluded paths (silent f√ºr Performance)
                }

                // üìù ERSTELLE DATEI-INFO (Memory-optimiert)
                FileInfo file;
                file.filePath = canonicalPath;
                file.fileName = fileInfo.fileName();
                file.size = fileInfo.size();
                file.lastModified = fileInfo.lastModified().toMSecsSinceEpoch();
                file.isLocal = true;

                currentBatch.append(file);
                totalFilesProcessed++;
                
                // üöÄ BATCH-VERARBEITUNG: Verarbeite wenn Batch voll ist
                if (currentBatch.size() >= BATCH_SIZE) {
                    qDebug() << "[Scanner] üì¶ Verarbeite Batch" << batchNumber << "mit" << currentBatch.size() << "Dateien";
                    
                    // F√ºge Batch zu allFiles hinzu
                    allFiles.append(currentBatch);
                    
                    // Progress-Update: FIXED Parameter Order (percentage, current, total)
                    int estimatedTotal = qMax(totalFilesProcessed, 1000); // Estimated total
                    // üõ°Ô∏è DIVISION-BY-ZERO SCHUTZ: estimatedTotal ist durch qMax gesch√ºtzt
                    int progress = (totalFilesProcessed * 100) / estimatedTotal;
                    emit scanProgress(progress, totalFilesProcessed, estimatedTotal);
                    emit scanStatusChanged(QString("Batch %1 verarbeitet (%2 Dateien)")
                                         .arg(batchNumber)
                                         .arg(totalFilesProcessed));
                    
                    // üßπ MEMORY-CLEANUP
                    currentBatch.clear();
                    currentBatch.reserve(BATCH_SIZE); // Pre-allocate f√ºr n√§chsten Batch
                    batchNumber++;
                    
                    // üîÑ KURZE PAUSE f√ºr GUI-Responsiveness
                    QApplication::processEvents();
                }
            }
        }
    }
    
    // üì¶ VERARBEITE LETZTEN BATCH
    if (!currentBatch.isEmpty()) {
        qDebug() << "[Scanner] üì¶ Verarbeite finalen Batch" << batchNumber << "mit" << currentBatch.size() << "Dateien";
        allFiles.append(currentBatch);
        totalFilesProcessed += currentBatch.size();
        currentBatch.clear();
    }
    
    // üìä FINAL STATISTICS
    qDebug() << "[Scanner] ‚úÖ Batch-optimierte Sammlung abgeschlossen:" << totalFilesProcessed << "Dateien in" << (batchNumber-1) << "Batches";
    
    emit filesCollected(allFiles.size());
    emit scanStatusChanged(QString("üìä %1 Dateien gesammelt (lokal: %2, netzwerk: %3)")
                          .arg(allFiles.size())
                          .arg(hasLocalDirectories ? "‚úÖ" : "‚ùå")
                          .arg(hasFtpDirectories ? "‚úÖ" : "‚ùå"));
    
    if (processedFiles.size() > allFiles.size())
    {
        qDebug() << "[Scanner] üîÑ" << (processedFiles.size() - allFiles.size()) << "Duplikate √ºbersprungen";
    }

    // ‚úÖ INTELLIGENTE WEITERLEITUNG basierend auf Datei-Typen
    if (hasLocalDirectories && !hasFtpDirectories) {
        // Nur lokale Dateien - sofort weiter zur Size-Filterung
        qDebug() << "[Scanner] üìÇ Nur lokale Dateien gefunden, starte Size-Filtering";
        filterBySize();
    } else if (!hasLocalDirectories && hasFtpDirectories) {
        // Nur FTP-Dateien - warte auf FTP-Verarbeitung
        qDebug() << "[Scanner] üì° Nur FTP-Dateien gefunden, warte auf" << pendingFtpDirectories.size() << "FTP-Verzeichnisse";
        emit scanStatusChanged(QString("Lade FTP-Verzeichnisse: 0/%1").arg(pendingFtpDirectories.size()));
    } else if (hasLocalDirectories && hasFtpDirectories) {
        // Beide Arten - lokale sind bereits da, warte auf FTP-Completion
        qDebug() << "[Scanner] üîÑ Parallel-Scan: Lokale Dateien fertig (" << allFiles.size() << "), warte auf" << pendingFtpDirectories.size() << "FTP-Verzeichnisse";
        emit scanStatusChanged(QString("Parallel: Lokal fertig (%1), FTP: 0/%2").arg(allFiles.size()).arg(pendingFtpDirectories.size()));
    } else {
        // Keine Dateien gefunden
        qDebug() << "[Scanner] ‚ùå Keine Dateien gefunden";
        filterBySize(); // Leerer Scan
    }
}

void Scanner::filterBySize()
{
    if (!scanning.load())
        return;

    emit scanStatusChanged("Sortiere nach Dateigr√∂√üe...");
    currentPhase = SIZE_FILTERING;

    // Group files by size
    for (const FileInfo &file : allFiles)
    {
        fileSizeGroups[file.size].append(file);
    }

    // ‚úÖ FIX: Behalte auch einzelne Dateien f√ºr Hash-Berechnung (Debug-Modus)
    // TEMPOR√ÑR: F√ºr FTP-Testing alle Dateien behalten statt nur potentielle Duplikate
    qDebug() << "[Scanner] üìä Size-Groups vor Filterung:" << fileSizeGroups.size() << "verschiedene Gr√∂√üen";
    
    // ORIGINAL-CODE (entfernt single files):
    // auto it = fileSizeGroups.begin();
    // while (it != fileSizeGroups.end())
    // {
    //     if (it.value().size() == 1)
    //     {
    //         it = fileSizeGroups.erase(it);
    //     }
    //     else
    //     {
    //         ++it;
    //     }
    // }
    
    // ‚úÖ FIX: Behalte alle Dateien (auch einzelne) f√ºr Hash-Berechnung
    qDebug() << "[Scanner] üìä Size-Groups nach Filterung:" << fileSizeGroups.size() << "verschiedene Gr√∂√üen (alle behalten)";

    int potentialDuplicates = 0;
    for (const auto &group : fileSizeGroups)
    {
        potentialDuplicates += group.size();
    }

    qDebug() << "[Scanner] üìä" << potentialDuplicates << "Dateien zur Hash-Berechnung hinzugef√ºgt";
    std::cout << "üìä " << potentialDuplicates << " Dateien zur Hash-Berechnung hinzugef√ºgt" << std::endl;

    // Phase 3: Start hashing
    startHashing();
}

void Scanner::startHashing()
{
    if (!scanning.load() || !hashEngine)
        return;

    emit scanStatusChanged("Berechne Hashes...");
    currentPhase = HASHING;
    
    std::cout << "[Scanner] üöÄüöÄüöÄ FORCING RADICAL PARALLEL f√ºr ALLE " << allFiles.size() << " Dateien!" << std::endl;
    
    // ‚úÖ Automatically detect and setup credentials for FTP files
    if (presetManager) {
        QSet<QString> ftpHosts;
        for (const FileInfo &file : allFiles) {
            if (file.filePath.startsWith("ftp://") || !file.isLocal) {
                QUrl url(file.filePath);
                if (url.isValid()) {
                    ftpHosts.insert(url.host());
                }
            }
        }
        
        // Setup credentials for any FTP hosts found
        for (const QString &host : ftpHosts) {
            LoginData login = presetManager->getLogin(host, 21);  
            if (login.isValid()) {
                hashEngine->setFtpCredentials(host, login.username, login.password);
                qDebug() << "[Scanner] üîê FTP-Credentials an HashEngine weitergeleitet f√ºr:" << host;
            } else {
                qWarning() << "[Scanner] ‚ö†Ô∏è Keine FTP-Credentials f√ºr HashEngine verf√ºgbar:" << host;
            }
        }
    }
    
    // üöÄ ALWAYS USE RADICAL PARALLEL PROCESSING for maximum performance
    QStringList allPaths;
    for (const FileInfo &file : allFiles) {
        allPaths.append(file.filePath);
    }
    
    // Force RADICAL PARALLEL processing for ALL files (local + FTP)
    std::cout << "[Scanner] üöÄ Forcing startRadicalParallelProcessing f√ºr " << allPaths.size() << " Dateien" << std::endl;
    startRadicalParallelProcessing(QStringList{scanDirectories.first()}); // Trigger 8-Engine system
    return; // Skip all old processing code - END OF METHOD
}

void Scanner::onHashCalculated(const QString &filePath, const QString &hash)
{
        
        std::cout << "[Scanner] üöÄ CONTROLLED: " << numParallelEngines 
                  << " Engines f√ºr " << totalFiles << " Dateien (FTP: " << (hasFtpFiles ? "JA" : "NEIN") << ")" << std::endl;
        
        for (int i = 0; i < numParallelEngines; i++) {
            int startIndex = i * chunkSize;
            int endIndex = qMin(startIndex + chunkSize, totalFiles);
            
            if (startIndex < totalFiles) {
                QList<FileInfo> chunk = allFiles.mid(startIndex, endIndex - startIndex);
                
                // Zeitversetzter Start f√ºr Server-Stabilit√§t
                int delay = i * 50; // 50ms zwischen Engines
                QTimer::singleShot(delay, this, [this, chunk, i]() {
                    processFileChunkParallel(chunk, i);
                });
                
                std::cout << "[Scanner] üöÄ Engine " << (i+1) << " ‚Üí " 
                          << chunk.size() << " Dateien (Delay: " << delay << "ms)" << std::endl;
            }
        }
        return; // Skip normal processing completely
    }
    
    QStringList filesToHash;
    
    // ÔøΩ OPTIMIZED: Use only files from optimized size+date groups instead of ALL files
    QMap<QString, QList<FileInfo>> dateSizeGroups;
    
    // Smart optimization: Skip files that cannot be duplicates
    for (auto &sizeGroup : fileSizeGroups)
    {
        if (sizeGroup.size() == 1) {
            continue;  // Skip unique sizes completely
        }
        
        bool hasNetworkFiles = false;
        // Check if group contains network files (FTP/SFTP etc.)
        for (const FileInfo &file : sizeGroup) {
            if (file.filePath.startsWith("ftp://") || file.filePath.startsWith("sftp://")) {
                hasNetworkFiles = true;
                break;
            }
        }
        
        if (hasNetworkFiles) {
            // For network files: Skip date filtering (unreliable timestamps)
            QString sizeOnlyKey = QString("size_%1").arg(sizeGroup.first().size);
            dateSizeGroups[sizeOnlyKey] = sizeGroup;
            qDebug() << "[Scanner] üì° Network-Gruppe (nur Size-Filter):" << sizeGroup.size() << "Dateien";
        } else {
            // For local files: Use size+date filtering for better optimization  
            QMap<QString, QList<FileInfo>> dateSubGroups;
            for (const FileInfo &file : sizeGroup) {
                QDateTime dateTime = QDateTime::fromSecsSinceEpoch(file.lastModified);
                QString dateKey = QString("%1_%2").arg(dateTime.toString("yyyy-MM-dd")).arg(file.size);
                dateSubGroups[dateKey].append(file);
            }
            
            // Only keep date groups with multiple files
            for (auto dateIt = dateSubGroups.begin(); dateIt != dateSubGroups.end(); ++dateIt) {
                if (dateIt.value().size() > 1) {
                    dateSizeGroups[dateIt.key()] = dateIt.value();
                }
            }
            qDebug() << "[Scanner] üìÅ Lokale Gruppe (Size+Date-Filter):" << dateSubGroups.size() << "Untergruppen";
        }
    }
    
    // Add optimized files to hash calculation
    QSet<QString> processedForHashing; // üõ°Ô∏è SCHUTZ: Verhindere doppelte Hash-Berechnung
    for (const auto &group : dateSizeGroups)
    {
        for (const FileInfo &file : group) {
            // üõ°Ô∏è NEUE SICHERUNG: Pr√ºfe ob Datei bereits zur Hash-Berechnung hinzugef√ºgt wurde
            QString canonicalPath = getCanonicalPath(file.filePath); // ‚úÖ URL-SAFE
            if (processedForHashing.contains(canonicalPath)) {
                qDebug() << "[Scanner] ‚ö†Ô∏è Datei bereits f√ºr Hashing vorgemerkt (√ºbersprungen):" << file.filePath.right(50);
                continue;
            }
            processedForHashing.insert(canonicalPath);
            filesToHash.append(file.filePath);
        }
    }

    qDebug() << "[Scanner] üîç Starte OPTIMIERTE Hash-Berechnung f√ºr" << filesToHash.size() << "Dateien";
    qDebug() << "[Scanner] ‚ö° Performance-Boost durch" << (allFiles.size() - filesToHash.size()) << "√ºbersprungene Unique-Dateien";
    
    // Handle case when ALL files are unique
    if (filesToHash.isEmpty()) {
        qDebug() << "[Scanner] ‚úÖ ALLE Dateien sind unique - keine Hash-Berechnung erforderlich!";
        emit scanStatusChanged("‚úÖ Alle Dateien sind unique - keine Duplikate gefunden!");
        
        QTimer::singleShot(500, this, [this]() {
            DuplicateGroups emptyResults;
            emit scanCompleted(emptyResults);
        });
        return;
    }

    qDebug() << "[Scanner] üîç Starte Hash-Berechnung f√ºr" << filesToHash.size() << "Dateien";
    qDebug() << "[Scanner] üìä" << filesToHash.size() << "Dateien zur Hash-Berechnung hinzugef√ºgt";
    emit hashingStarted(filesToHash.size());
    hashEngine->calculateMultipleHashes(filesToHash);
}

void Scanner::onHashCalculated(const QString &filePath, const QString &hash)
{
    if (!scanning.load())
        return;

    // üõ°Ô∏è SICHERUNG: Verhindere Doppelbearbeitung bereits berechneter Hashes
    if (globalHashedFiles.contains(filePath)) {
        qDebug() << "[Scanner] ‚ö†Ô∏è Hash bereits berechnet f√ºr:" << filePath.right(50);
        return;
    }
    globalHashedFiles.insert(filePath);

    qDebug() << "[Scanner] üìä Hash berechnet f√ºr:" << filePath.right(50) << "‚Üí" << hash.left(16);

    // ‚úÖ FIX: Update hash in BOTH fileSizeGroups AND allFiles
    bool hashUpdated = false;
    
    // Update in fileSizeGroups
    for (auto &group : fileSizeGroups)
    {
        for (FileInfo &file : group)
        {
            if (file.filePath == filePath)
            {
                // üõ°Ô∏è ZUS√ÑTZLICHE SICHERUNG: Verhindere Hash-√úberschreibung
                if (!file.hash.isEmpty() && file.hash != hash) {
                    qWarning() << "[Scanner] ‚ö†Ô∏è Hash-Konflikt f√ºr" << filePath.right(50) 
                              << "- Alt:" << file.hash.left(16) << "Neu:" << hash.left(16);
                }
                file.hash = hash;
                hashUpdated = true;
                break;
            }
        }
        if (hashUpdated) break;
    }
    
    // ‚úÖ CRITICAL FIX: Also update in allFiles (needed for hash comparison)
    for (FileInfo &file : allFiles)
    {
        if (file.filePath == filePath)
        {
            file.hash = hash;
            qDebug() << "[Scanner] ‚úÖ Hash auch in allFiles gesetzt f√ºr:" << filePath.right(50);
            break;
        }
    }

    // ‚úÖ FIX: Korrekte Progress-Berechnung f√ºr QMap<qint64, QList<FileInfo>>
    int totalFilesInGroups = 0;
    int hashedFilesInGroups = 0;
    
    // Iteriere √ºber alle Gr√∂√üengruppen in der Map
    for (auto groupIt = fileSizeGroups.begin(); groupIt != fileSizeGroups.end(); ++groupIt)
    {
        const QList<FileInfo> &filesInGroup = groupIt.value();
        for (const FileInfo &file : filesInGroup)
        {
            totalFilesInGroups++;
            if (!file.hash.isEmpty() && file.hash != "FTP_SKIPPED" && file.hash != "FTP_DOWNLOAD_FAILED")
            {
                hashedFilesInGroups++;
            }
        }
    }
    
    // ‚úÖ FIX: Emit progress with PERCENTAGE als erstem Parameter f√ºr MainWindow
    int percentage = (totalFilesInGroups > 0) ? (hashedFilesInGroups * 100 / totalFilesInGroups) : 0;
    emit scanProgress(percentage, hashedFilesInGroups, totalFilesInGroups); // PERCENTAGE ZUERST!
    
    qDebug() << "[Scanner] üìä Hash-Progress:" << hashedFilesInGroups << "/" << totalFilesInGroups << "abgeschlossen (" << percentage << "%)";
    
    // ‚úÖ FORCE COMPLETE bei 99% oder mehr - verhindert H√§ngen bei letzten Dateien
    bool forceComplete = (percentage >= 99 && hashedFilesInGroups > 0);
    bool allHashesReady = (hashedFilesInGroups >= totalFilesInGroups && totalFilesInGroups > 0) || forceComplete;
    
    if (allHashesReady)
    {
        if (forceComplete) {
            qDebug() << "[Scanner] üöÄ FORCE COMPLETE bei 99%+ aktiviert (" << percentage << "% - " << hashedFilesInGroups << "/" << totalFilesInGroups << ")";
        }
        qDebug() << "[Scanner] ‚úÖ Alle Hashes berechnet, starte Vergleich";
        compareHashes();
    }
}

void Scanner::compareHashes()
{
    if (!scanning.load())
        return;

    emit scanStatusChanged("üîÑ Vergleiche Duplikate (lokal ‚Üî netzwerk)...");
    currentPhase = COMPARING;
    emit comparingStarted();

    // ‚úÖ TIMEOUT-SCHUTZ: Verhindere H√§ngen bei gro√üen Datens√§tzen
    QElapsedTimer elapsedTimer;
    elapsedTimer.start();
    const qint64 MAX_COMPARE_TIME_MS = 300000; // 5 Minuten Maximum
    
    qDebug() << "[Scanner] üöÄ Starte Hash-Vergleich f√ºr" << allFiles.size() << "Dateien";

    // ‚úÖ PHASE 1: Hash-Gruppierung mit Progress und Timeout
    emit scanProgress(0, 0, allFiles.size());
    emit scanStatusChanged("üìä Phase 1/3: Gruppiere Dateien nach Hash...");
    
    int processedFiles = 0;
    
    // Group files by hash with progress updates and timeout checking
    for (const FileInfo &file : allFiles)
    {
        // ‚úÖ TIMEOUT-CHECK: Breche ab wenn zu lange dauert
        if (elapsedTimer.elapsed() > MAX_COMPARE_TIME_MS) {
            qWarning() << "[Scanner] ‚è∞ Timeout beim Hash-Vergleich nach" 
                      << (elapsedTimer.elapsed() / 1000) << "Sekunden - breche ab";
            emit scanStatusChanged("‚è∞ Timeout beim Vergleich - verwende bisherige Ergebnisse");
            break;
        }
        
        if (!scanning.load()) {
            qDebug() << "[Scanner] üõë Scan gestoppt w√§hrend Hash-Vergleich";
            return;
        }
        
        if (!file.hash.isEmpty())
        {
            hashGroups[file.hash].append(file);
        }
        
        processedFiles++;
        
        // Progress update every 500 files (h√§ufiger f√ºr responsiveness)
        if (processedFiles % 500 == 0 || processedFiles == allFiles.size()) {
            int progressPercent = (processedFiles * 33) / allFiles.size(); // 33% for Phase 1
            emit scanProgress(progressPercent, processedFiles, allFiles.size());
            emit scanStatusChanged(QString("üìä Phase 1/3: Gruppiert %1/%2 Dateien (%3%) - Zeit: %4s")
                                  .arg(processedFiles).arg(allFiles.size()).arg(progressPercent)
                                  .arg(elapsedTimer.elapsed() / 1000));
            
            // ‚úÖ GUI-UPDATE: Gib GUI Zeit f√ºr Updates
            QApplication::processEvents();
        }
    }
    
    // ‚úÖ DEBUG: Zeige Hash-Statistiken
    qDebug() << "[Scanner] üîç Hash-Debug:" << hashGroups.size() << "eindeutige Hashes f√ºr" << allFiles.size() << "Dateien";
    for (auto it = hashGroups.begin(); it != hashGroups.end(); ++it) {
        if (it.value().size() > 1) {
            qDebug() << "[Scanner] üîÑ Hash" << it.key().left(8) << "hat" << it.value().size() << "Dateien:";
            for (const FileInfo &file : it.value()) {
                qDebug() << "    -" << file.filePath << "(" << file.size << "bytes)";
            }
        }
    }

    // ‚úÖ PHASE 2: Entferne eindeutige Hashes mit Progress und Timeout
    emit scanProgress(33, allFiles.size(), allFiles.size());
    emit scanStatusChanged("üîç Phase 2/3: Filtere Duplikate...");
    
    int totalHashes = hashGroups.size();
    int processedHashes = 0;
    
    qDebug() << "[Scanner] üîç Phase 2: Filtere" << totalHashes << "Hash-Gruppen";
    
    // Remove unique hashes with timeout protection
    auto it = hashGroups.begin();
    while (it != hashGroups.end())
    {
        // ‚úÖ TIMEOUT-CHECK
        if (elapsedTimer.elapsed() > MAX_COMPARE_TIME_MS) {
            qWarning() << "[Scanner] ‚è∞ Timeout in Phase 2 - verwende bisherige Duplikate";
            emit scanStatusChanged("‚è∞ Timeout in Phase 2 - verwende bisherige Duplikate");
            break;
        }
        
        if (!scanning.load()) {
            qDebug() << "[Scanner] üõë Scan gestoppt in Phase 2";
            return;
        }
        
        if (it.value().size() == 1)
        {
            it = hashGroups.erase(it);
        }
        else
        {
            ++it;
        }
        
        processedHashes++;
        
        // Progress update every 50 hashes (h√§ufiger)
        if (processedHashes % 50 == 0 || processedHashes == totalHashes) {
            int progressPercent = 33 + (processedHashes * 33) / totalHashes; // 33-66% for Phase 2
            emit scanProgress(progressPercent, processedHashes, totalHashes);
            emit scanStatusChanged(QString("üîç Phase 2/3: Gefiltert %1/%2 Hash-Gruppen (%3%) - Zeit: %4s")
                                  .arg(processedHashes).arg(totalHashes).arg(progressPercent)
                                  .arg(elapsedTimer.elapsed() / 1000));
            
            // ‚úÖ GUI-UPDATE
            QApplication::processEvents();
        }
    }

    // ‚úÖ PHASE 3: Statistiken mit Progress
    emit scanProgress(66, 0, hashGroups.size());
    emit scanStatusChanged("üìà Phase 3/3: Erstelle Duplikat-Statistiken...");
    
    // ‚úÖ NEU: Statistiken f√ºr lokale vs Netzwerk-Duplikate
    int localOnlyGroups = 0;
    int networkOnlyGroups = 0;
    int mixedGroups = 0;
    int analyzedGroups = 0;
    
    for (const auto &hashGroup : hashGroups) {
        bool hasLocal = false;
        bool hasNetwork = false;
        
        for (const FileInfo &file : hashGroup) {
            if (file.isLocal) {
                hasLocal = true;
            } else {
                hasNetwork = true;
            }
        }
        
        if (hasLocal && hasNetwork) {
            mixedGroups++;
        } else if (hasLocal) {
            localOnlyGroups++;
        } else if (hasNetwork) {
            networkOnlyGroups++;
        }
        
        analyzedGroups++;
        
        // Progress update every 10 groups
        if (analyzedGroups % 10 == 0 || analyzedGroups == hashGroups.size()) {
            int progressPercent = 66 + (analyzedGroups * 34) / hashGroups.size(); // 66-100% for Phase 3
            emit scanProgress(progressPercent, analyzedGroups, hashGroups.size());
            emit scanStatusChanged(QString("üìà Phase 3/3: Analysiert %1/%2 Duplikat-Gruppen (%3%)")
                                  .arg(analyzedGroups).arg(hashGroups.size()).arg(progressPercent));
        }
    }

    std::cout << "üîç " << hashGroups.size() << " Duplikat-Gruppen gefunden:" << std::endl;
    std::cout << "   üìÇ Nur lokal: " << localOnlyGroups << " Gruppen" << std::endl;
    std::cout << "   üì° Nur netzwerk: " << networkOnlyGroups << " Gruppen" << std::endl;
    std::cout << "   üîÑ Lokal ‚Üî Netzwerk: " << mixedGroups << " Gruppen" << std::endl;

    // ‚úÖ FINAL: 100% Progress vor generateResults()
    emit scanProgress(100, hashGroups.size(), hashGroups.size());
    emit scanStatusChanged(QString("‚úÖ Duplikat-Analyse abgeschlossen: %1 Gruppen gefunden")
                          .arg(hashGroups.size()));

    generateResults();
}

void Scanner::generateResults()
{
    if (!scanning.load())
        return;

    emit scanStatusChanged("Generiere Ergebnisse (lokal + netzwerk)...");
    currentPhase = COMPLETED;

    DuplicateGroups results;
    int crossNetworkDuplicates = 0;

    for (const auto &hashGroup : hashGroups)
    {
        if (hashGroup.size() < 2)
            continue;

        DuplicateGroup group;
        QList<FileInfo> files = hashGroup;

        // ‚úÖ NEU: Pr√ºfe ob es sich um lokale ‚Üî Netzwerk Duplikate handelt
        bool hasLocal = false;
        bool hasNetwork = false;
        for (const FileInfo &file : files) {
            if (file.isLocal) {
                hasLocal = true;
            } else {
                hasNetwork = true;
            }
        }
        
        if (hasLocal && hasNetwork) {
            crossNetworkDuplicates++;
        }

        // Sort by modification time (newest first by default), but prefer local files as originals
        std::sort(files.begin(), files.end(), [](const FileInfo &a, const FileInfo &b)
                  { 
                      // ‚úÖ NEU: Bevorzuge lokale Dateien als Original (sicherer)
                      if (a.isLocal != b.isLocal) {
                          return a.isLocal > b.isLocal; // Lokale Dateien zuerst
                      }
                      return a.lastModified > b.lastModified; // Dann nach Datum
                  });

        // First file is original (preferably local), rest are duplicates
        group.original = files.takeFirst();
        group.duplicates = files;
        group.hash = group.original.hash;
        group.size = group.original.size;

        results.groups.append(group);
        results.duplicateFiles += group.duplicates.size();
        results.duplicateSize += group.size * group.duplicates.size();
    }

    results.totalFiles = allFiles.size();

    scanning.store(false);
    currentPhase = IDLE;

    // ‚úÖ DEBUG: Detaillierte Ergebnis-Analyse
    qDebug() << "[Scanner] üìä FINALE STATISTIKEN:";
    qDebug() << "    - Verarbeitete Dateien:" << results.totalFiles;
    qDebug() << "    - Duplikat-Gruppen:" << results.groups.size();
    qDebug() << "    - Duplikat-Dateien:" << results.duplicateFiles;
    qDebug() << "    - Gesparte Gr√∂√üe:" << (results.duplicateSize / (1024*1024)) << "MB";

    std::cout << "‚úÖ Parallel-Scan abgeschlossen: " << results.groups.size()
              << " Duplikat-Gruppen mit " << results.duplicateFiles << " Duplikaten" << std::endl;
    std::cout << "   üîÑ Lokal ‚Üî Netzwerk Duplikate: " << crossNetworkDuplicates << " Gruppen" << std::endl;

    emit scanCompleted(results);
    emit scanStatusChanged("Parallel-Scan abgeschlossen (lokal + netzwerk)");
}

void Scanner::onFtpFilesReceived(const QString &directory, const QStringList &files, bool success)
{
    qDebug() << "[Scanner] üìÑ FTP-Dateien empfangen f√ºr:" << directory << "Files:" << files.size() << "Success:" << success;
    
    if (!success) {
        qWarning() << "[Scanner] ‚ö†Ô∏è FTP-Fehler beim Laden von:" << directory;
        return;
    }
    
    // Find the full FTP URL for this directory path
    QString fullFtpUrl;
    for (const QString &pendingUrl : pendingFtpDirectories) {
        QUrl url(pendingUrl);
        if (url.path() == directory) {
            fullFtpUrl = pendingUrl;
            break;
        }
    }
    
    if (fullFtpUrl.isEmpty()) {
        qWarning() << "[Scanner] ‚ö†Ô∏è Keine entsprechende FTP-URL gefunden f√ºr:" << directory;
        return;
    }
    
    // Extract host from full FTP URL for file path construction
    QUrl ftpUrl(fullFtpUrl);
    QString host = ftpUrl.host();
    QString basePath = ftpUrl.path();
    
    // Add all files to allFiles list
    for (const QString &encodedFile : files) {
        // ‚úÖ FIX: Parse encoded "filename|size" format
        QStringList parts = encodedFile.split('|');
        QString fileName = parts.size() > 0 ? parts[0] : encodedFile;
        qint64 fileSize = parts.size() > 1 ? parts[1].toLongLong() : 0;
        
        // ‚úÖ URL-KODIERUNG: Spaces und Sonderzeichen f√ºr FTP-URLs kodieren
        QString encodedFileName = QUrl::toPercentEncoding(fileName);
        
        FileInfo fileInfo;
        fileInfo.filePath = QString("ftp://%1%2/%3").arg(host, basePath, encodedFileName);
        fileInfo.fileName = fileName; // Original-Dateiname f√ºr Anzeige
        fileInfo.size = fileSize; // ‚úÖ FIX: Use real file size from FTP LIST
        fileInfo.lastModified = QDateTime::currentSecsSinceEpoch();
        fileInfo.hash = "";
        fileInfo.isLocal = false; // ‚úÖ NEU: Markiere als Netzwerk-Datei
        fileInfo.networkType = "FTP"; // ‚úÖ NEU: Netzwerk-Typ
        
        allFiles.append(fileInfo);
        qDebug() << "[Scanner] ‚úÖ Added FTP file:" << fileInfo.filePath << "Size:" << fileSize << "bytes";
    }
    
    // Mark this directory as completed
    completedFtpDirectories.append(directory);
    ftpDirectoriesProcessed++;
    
    // ‚úÖ NEU: Z√§hle lokale und FTP-Dateien separat f√ºr bessere Anzeige
    int localFiles = 0;
    int ftpFiles = 0;
    for (const FileInfo &file : allFiles) {
        if (file.isLocal) {
            localFiles++;
        } else {
            ftpFiles++;
        }
    }
    
    emit scanStatusChanged(QString("Parallel: Lokal %1, FTP %2/%3 (%4 Dateien)")
                          .arg(localFiles)
                          .arg(ftpDirectoriesProcessed)
                          .arg(pendingFtpDirectories.size())
                          .arg(ftpFiles));
    
    // Check if all FTP directories are processed
    if (completedFtpDirectories.size() >= pendingFtpDirectories.size()) {
        qDebug() << "[Scanner] ‚úÖ Alle FTP-Verzeichnisse verarbeitet (lokal:" << localFiles << ", ftp:" << ftpFiles << "), starte Size-Filtering";
        QTimer::singleShot(100, this, [this]() {
            filterBySize(); // ‚úÖ KORREKTUR: Erst Size-Filtering f√ºr alle Dateien
        });
    }
}

void Scanner::collectFtpFiles(const QString &ftpDirectory, QSet<QString> &processedFiles)
{
    qDebug() << "[Scanner] üì° FTP-Dateien sammeln f√ºr:" << ftpDirectory;
    
    // Extract IP and path from FTP URL: ftp://192.168.1.224/sdb/Comedy/
    QUrl ftpUrl(ftpDirectory);
    QString host = ftpUrl.host();
    QString path = ftpUrl.path();
    
    if (host.isEmpty()) {
        qWarning() << "[Scanner] ‚ö†Ô∏è Ung√ºltiger FTP-Pfad:" << ftpDirectory;
        return;
    }
    
    // ‚úÖ CHUNK-BASIERTE PROCESSING: Verhindere Memory-Probleme und H√§ngen
    std::cout << "[Scanner] üöÄ CHUNK-PROCESSING: Memory-safe FTP-Collection f√ºr " 
              << ftpDirectory.toStdString() << std::endl;
    
    // ‚úÖ KRITISCH: Pr√ºfe PresetManager-Verf√ºgbarkeit
    if (!presetManager) {
        qCritical() << "[Scanner] ‚ùå FATAL: PresetManager ist null! Kann keine FTP-Credentials abrufen.";
        qCritical() << "[Scanner] üí° MainWindow muss m_scanner->setPresetManager(m_presetManager) aufrufen!";
        return;
    }
    
    // ‚úÖ KORREKTUR: Hole Credentials aus PresetManager f√ºr gespeicherte Logins
    LoginData login = presetManager->getLogin(host, 21);
    if (!login.isValid()) {
        qWarning() << "[Scanner] ‚ö†Ô∏è Keine Login-Daten f√ºr" << host << ":21 gefunden";
        qWarning() << "[Scanner] üí° Stellen Sie sicher, dass FTP-Credentials gespeichert sind";
        return;
    }
    
    qDebug() << "[Scanner] üîê Verwende Credentials:" << login.username << "f√ºr" << host;
    
    // ‚úÖ CHUNK-PROCESSING: Erstelle FtpClient mit 1000er-Chunks (wie im erfolgreichen Test)
    FtpClient *urlSpecificClient = new FtpClient(this);
    urlSpecificClient->setCredentials(host, 21, login.username, login.password);
    
    // Add to pending directories list for tracking
    if (!pendingFtpDirectories.contains(ftpDirectory)) {
        pendingFtpDirectories.append(ftpDirectory);
    }
    
    qDebug() << "[Scanner] üìÇ Starte CHUNK-basierten FTP-Datei-Scan f√ºr:" << host << path;
    
    // ‚úÖ URL-SAFE FileName Extraction (bew√§hrt aus test_chunk_processing.cpp)
    auto safeExtractFileName = [](const QString &fullPath) -> QString {
        if (fullPath.startsWith("ftp://") || fullPath.startsWith("sftp://") || fullPath.startsWith("smb://")) {
            QUrl url(fullPath);
            QString path = url.path();
            return path.split('/').last();
        } else {
            return QFileInfo(fullPath).fileName();
        }
    };
    
    // ‚úÖ CHUNK-KONSTANTEN (bew√§hrt aus erfolgreichem Test)
    const int CHUNK_SIZE = 1000;  // Getestet mit 28.679 Dateien
    const int MEMORY_CLEANUP_INTERVAL = 5;  // Cleanup alle 5 Chunks
    
    // ‚úÖ CHUNK-PROCESSING Signal Connection (verhindert QEventLoop-H√§ngen)
    connect(urlSpecificClient, &FtpClient::listFinished,
            this, [this, ftpDirectory, urlSpecificClient, safeExtractFileName, CHUNK_SIZE, MEMORY_CLEANUP_INTERVAL]
            (const QStringList &allDirs, bool success) {
        
        qDebug() << "[Scanner] üìÑ FTP-Verzeichnisse empfangen f√ºr:" << ftpDirectory << "Dirs:" << allDirs.size() << "Success:" << success;
        
        if (success && !allDirs.isEmpty()) {
            int totalDirs = allDirs.size();
            int processedCount = 0;
            int chunkNumber = 1;
            int totalChunks = (totalDirs + CHUNK_SIZE - 1) / CHUNK_SIZE;
            
            qDebug() << "[Scanner] üöÄ CHUNK-PROCESSING:" << totalDirs << "Verzeichnisse in" << totalChunks << "Chunks √†" << CHUNK_SIZE;
            
            // ‚úÖ CHUNK-basierte Verarbeitung (bew√§hrt aus Test)
            for (int chunkStart = 0; chunkStart < totalDirs; chunkStart += CHUNK_SIZE) {
                int chunkEnd = qMin(chunkStart + CHUNK_SIZE, totalDirs);
                int chunkSize = chunkEnd - chunkStart;
                
                qDebug() << "[Scanner] üîÑ Chunk" << chunkNumber << "von" << totalChunks 
                         << "(" << chunkSize << "Verzeichnisse)";
                
                // Verarbeite aktuellen Chunk
                for (int i = chunkStart; i < chunkEnd; ++i) {
                    if (i >= allDirs.size()) break;
                    
                    const QString &dir = allDirs.at(i);
                    if (dir.isEmpty()) continue;
                    
                    QString fullPath = dir;  // allDirs enth√§lt bereits vollst√§ndige Pfade
                    
                    // ‚úÖ EMIT CURRENT FILE PROCESSING f√ºr Real-time UI Update
                    QFileInfo tempInfo(fullPath);
                    emit currentFileProcessing(tempInfo.fileName(), "FTP Collecting", processedCount + 1, totalDirs);
                    
                    // ‚úÖ URL-Safe FileName Extraction
                    QString fileName = safeExtractFileName(fullPath);
                    
                    // ‚úÖ DEDUPLICATION: Check global processed files
                    QString canonicalPath = QUrl(fullPath).toString();
                    if (globalProcessedFiles.contains(canonicalPath)) continue;
                    globalProcessedFiles.insert(canonicalPath);
                    
                    // ‚úÖ Memory-Check (verhindert √úberlauf)
                    if (allFiles.size() > 100000) {
                        qWarning() << "[Scanner] ‚ö†Ô∏è Memory-Limit erreicht - stoppe bei" << allFiles.size() << "Dateien";
                        break;
                    }
                    
                    // ‚úÖ LIGHTNING-FAST: FileInfo creation
                    FileInfo ftpFile;
                    ftpFile.filePath = fullPath;
                    ftpFile.fileName = fileName;
                    ftpFile.size = 0;
                    ftpFile.lastModified = 1640995200; // Fixed timestamp
                    ftpFile.isLocal = false;
                    ftpFile.networkType = QString("FTP");
                    
                    allFiles.append(ftpFile);
                    processedCount++;
                }
                
                // ‚úÖ Memory-Cleanup (alle 5 Chunks wie im Test)
                if (chunkNumber % MEMORY_CLEANUP_INTERVAL == 0) {
                    qDebug() << "[Scanner] üßπ Memory-Cleanup nach Chunk" << chunkNumber;
                    globalProcessedFiles.squeeze();
                }
                
                // ‚úÖ Progress-Update (alle 1000 Verzeichnisse) - FIXED Parameter Order
                if (processedCount % 1000 == 0 || processedCount == totalDirs) {
                    qDebug() << "[Scanner] ‚ö°" << processedCount << "/" << totalDirs << "dirs processed";
                    int progress = totalDirs > 0 ? 
                        qRound((double(processedCount) / double(totalDirs)) * 100.0) : 0;
                    emit scanProgress(progress, processedCount, totalDirs);
                    emit scanStatusChanged(QString("‚ö° FTP-Verzeichnisse: %1/%2")
                                         .arg(processedCount).arg(totalDirs));
                }
                
                chunkNumber++;
            }
            
            qDebug() << "[Scanner] ‚úÖ FTP-Verzeichnisse verarbeitet:" << processedCount << "von" << totalDirs << "Verzeichnissen";
        } else {
            qWarning() << "[Scanner] ‚ö†Ô∏è FTP-Fehler beim Laden von:" << ftpDirectory;
        }
        
        // ‚úÖ CLEANUP: Entferne aus pending list und bereinige Client
        pendingFtpDirectories.removeAll(ftpDirectory);
        urlSpecificClient->deleteLater();
        
        // ‚úÖ PROGRESS CHECK: Pr√ºfe ob alle FTP-Verzeichnisse fertig sind
        checkScanProgress();
    });
    
    // ‚úÖ STARTE FTP-Dateiliste ohne QEventLoop (verhindert H√§ngen)
    // WICHTIG: Verwende list() f√ºr listFinished Signal!
    urlSpecificClient->list(path);
}

void Scanner::checkScanProgress()
{
    qDebug() << "[Scanner] üîç Pr√ºfe Scan-Fortschritt - Pending FTP:" << pendingFtpDirectories.size();
    
    // Wenn alle FTP-Operationen abgeschlossen sind, starte die Hash-Berechnung
    if (pendingFtpDirectories.isEmpty()) {
        qDebug() << "[Scanner] ‚úÖ Alle FTP-Verzeichnisse geladen - starte Hash-Berechnung";
        
        // ‚úÖ FIX: Group files by size BEFORE starting hash calculation
        emit scanStatusChanged("Sortiere nach Dateigr√∂√üe...");
        currentPhase = SIZE_FILTERING;

        // Group files by size (required for progress calculation)
        for (const FileInfo &file : allFiles)
        {
            fileSizeGroups[file.size].append(file);
        }
        
        qDebug() << "[Scanner] üìä Size-Groups erstellt:" << fileSizeGroups.size() << "verschiedene Gr√∂√üen f√ºr" << allFiles.size() << "Dateien";
        
        // Update status and start hashing
        emit scanStatusChanged(QString("üìÅ %1 eindeutige Dateien gesammelt (lokal: ‚úÖ, netzwerk: ‚úÖ)").arg(allFiles.size()));
        
        // Start hash calculation phase
        if (!allFiles.isEmpty()) {
            emit scanStatusChanged("Berechne Hash-Werte...");
            qDebug() << "[Scanner] üîç Starte Hash-Berechnung f√ºr" << allFiles.size() << "Dateien";
            startHashing();
        } else {
            qDebug() << "[Scanner] ‚ö†Ô∏è Keine Dateien zum Hashen gefunden";
            DuplicateGroups emptyGroups;
            emit scanCompleted(emptyGroups);
        }
    }
}

// üõ°Ô∏è NEUE FUNKTION: Deduplication-Caches leeren
void Scanner::clearDeduplicationCaches()
{
    globalProcessedFiles.clear();
    globalHashedFiles.clear();
    qDebug() << "[Scanner] üõ°Ô∏è Deduplication-Caches geleert";
}

// üõ°Ô∏è NEUE FUNKTION: Pr√ºfung ob Datei bereits verarbeitet wurde
bool Scanner::isFileAlreadyProcessed(const QString &filePath)
{
    QString canonicalPath = getCanonicalPath(filePath); // ‚úÖ URL-SAFE
    return globalProcessedFiles.contains(canonicalPath);
}

void Scanner::processNextFile()
{
    // Currently not used - hashing is handled by HashEngine
}

// üß† NPU-related methods
void Scanner::setNpuEnabled(bool enabled)
{
    npuEnabled = enabled;
    qDebug() << "[Scanner] üß† NPU enabled set to" << npuEnabled;
}

void Scanner::onNpuImageBatchProcessed(const QStringList &processedImages)
{
    qDebug() << "[Scanner] üé® NPU-Bildverarbeitung abgeschlossen:" << processedImages.size() << "Bilder verarbeitet";
    
    // üéØ LIVE-NPU-UPDATES f√ºr jedes verarbeitete Bild
    for (int i = 0; i < processedImages.size(); ++i) {
        QString imagePath = processedImages.at(i);
        QString fileName = QFileInfo(imagePath).fileName();
        
        // üìä LIVE-AKTIVIT√ÑTS-UPDATE an GUI senden - RE-ENABLED: NPU emit to GUI
        emit currentFileProcessing(fileName, "NPU-Bildanalyse", i + 1, processedImages.size());
        emit processActivityUpdate("NPU-Bildverarbeitung", 
                                   QString("Feature-Extraktion: %1").arg(fileName));
    }
    
    // Statistiken f√ºr NPU-Verarbeitung - RE-ENABLED: NPU emit to GUI
    emit scanStatusChanged(QString("üß† NPU-Bildverarbeitung: %1 Bilder analysiert").arg(processedImages.size()));
    
    // üöÄ NPU-AKTIVIT√ÑTS-UPDATE f√ºr Activity-Indicator - RE-ENABLED: NPU emit to GUI
    emit npuActivityUpdate(processedImages.size(), 0); // Noch keine Duplikate gefunden
}

// üóëÔ∏è FTP deletion callback
void Scanner::onFtpRemoveFinished(const QString &remoteFile, bool ok)
{
    deleteAttempted++;
    if (ok) deleteSucceeded++;
    emit deleteProgress(remoteFile, ok, ok ? "FTP gel√∂scht" : "FTP l√∂schen fehlgeschlagen");
    if (deleteAttempted == 0) return; // shouldn't happen
}

// ÔøΩ FTP Directory Collection Wrapper f√ºr MEGA-PARALLEL
void Scanner::collectFtpDirectory(const QString &ftpDirectory)
{
    std::cout << "[Scanner] üì° MEGA-PARALLEL FTP-Sammlung f√ºr: " << ftpDirectory.toStdString() << std::endl;
    
    // üåê NEW: Test f√ºr Multi-Connection Support
    QUrl ftpUrl(ftpDirectory);
    QString host = ftpUrl.host();
    int port = ftpUrl.port(21);
    
    if (!presetManager) {
        qCritical() << "[Scanner] ‚ùå PresetManager nicht verf√ºgbar f√ºr Multi-Connection Test";
        return;
    }
    
    LoginData login = presetManager->getLogin(host, port);
    if (!login.isValid()) {
        qWarning() << "[Scanner] ‚ö†Ô∏è Keine Login-Daten f√ºr Multi-Connection Test:" << host;
        return;
    }
    
    // üåê STEP 1: Test FTP Connection Limit
    int maxConnections = testFtpConnectionLimit(host, port, login.username, login.password);
    std::cout << "[Scanner] üåê FTP-Server " << host.toStdString() 
              << " unterst√ºtzt max. " << maxConnections << " parallele Verbindungen" << std::endl;
    
    if (maxConnections > 1) {
        // üöÄ MULTI-CONNECTION: Nutze parallele Verbindungen
        collectFtpDirectoryMultiConnection(ftpDirectory);
    } else {
        // üîí SINGLE-CONNECTION: Fallback zu normaler Verarbeitung
        QSet<QString> processedFiles;
        collectFtpFiles(ftpDirectory, processedFiles);
    }
    
    std::cout << "[Scanner] ‚úÖ FTP-Sammlung abgeschlossen f√ºr: " << ftpDirectory.toStdString() << std::endl;
}

// ÔøΩüöÄüöÄüöÄ LUDICROUS-SPEED: Ultra-Parallel file collection
void Scanner::collectFilesMultithreaded()
{
    std::cout << "[Scanner] üöÄ MODERATE-THREADING: Starte sichere parallele Dateisammlung" << std::endl;
    emit scanStatusChanged("üöÄ MODERATE-THREADING: Sichere parallele Dateisammlung gestartet...");
    
    QSet<QString> processedFiles;
    allFiles.clear();
    
    // Separiere lokale und FTP-Verzeichnisse
    QStringList localDirectories;
    QStringList ftpDirectories;
    for (const QString &directory : scanDirectories) {
        if (directory.startsWith("ftp://") || directory.startsWith("sftp://") || directory.startsWith("smb://")) {
            ftpDirectories.append(directory);
        } else {
            localDirectories.append(directory);
        }
    }
    
    // üöÄ MODERATE: Verarbeite FTP-Verzeichnisse mit kontrollierter Parallelit√§t
    if (!ftpDirectories.isEmpty()) {
        std::cout << "[Scanner] üì° FTP-Verzeichnisse erkannt: " << ftpDirectories.size() << " - starte KONTROLLIERTE Verarbeitung" << std::endl;
        
        for (const QString &ftpDir : ftpDirectories) {
            // üåê SAFE: Kontrollierte FTP-Verarbeitung
            QTimer::singleShot(0, this, [this, ftpDir]() {
                collectFtpDirectoryRadicalParallelSimple(ftpDir);
            });
        }
    }
    
    // Wenn keine lokalen Verzeichnisse, aber FTP vorhanden, warte auf FTP-Completion
    if (localDirectories.isEmpty() && !ftpDirectories.isEmpty()) {
        std::cout << "[Scanner] üì° Nur FTP-Verzeichnisse - warte auf FTP-Completion" << std::endl;
        // Starte Timer um auf FTP-Completion zu warten
        QTimer::singleShot(1000, this, [this]() {
            if (allFiles.isEmpty()) {
                std::cout << "[Scanner] ‚ö†Ô∏è FTP-Sammlung noch leer, warte weitere 2s..." << std::endl;
                QTimer::singleShot(2000, this, [this]() {
                    std::cout << "[Scanner] ‚úÖ FTP-Sammlung abgeschlossen mit " << allFiles.size() << " Dateien" << std::endl;
                    emit scanPhaseCompleted(COLLECTING);
                });
            } else {
                std::cout << "[Scanner] ‚úÖ FTP-Sammlung erfolgreich mit " << allFiles.size() << " Dateien" << std::endl;
                emit scanPhaseCompleted(COLLECTING);
            }
        });
        return;
    }
    
    if (localDirectories.isEmpty()) {
        emit scanPhaseCompleted(COLLECTING);
        return;
    }
    
    // üöÄüöÄüöÄ LUDICROUS STRATEGY: Ultra-aggressive directory splitting f√ºr maximale Parallelit√§t
    QStringList expandedDirectories;
    for (const QString &directory : localDirectories) {
        QDir dir(directory);
        QStringList subDirs = dir.entryList(QDir::Dirs | QDir::NoDotAndDotDot);
        
        if (subDirs.size() > 3) {  // 10 ‚Üí 3: Noch aggressiver aufteilen
            // Gro√üe Verzeichnisse: Jedes Unterverzeichnis als separaten Thread
            for (const QString &subDir : subDirs) {
                QString subDirPath = dir.absoluteFilePath(subDir);
                expandedDirectories.append(subDirPath);
                
                // üöÄ LUDICROUS: Auch Sub-Sub-Verzeichnisse separat verarbeiten
                QDir subDir2(subDirPath);
                QStringList subSubDirs = subDir2.entryList(QDir::Dirs | QDir::NoDotAndDotDot);
                if (subSubDirs.size() > 2) {  // Noch tiefere Aufteilung
                    for (const QString &subSubDir : subSubDirs) {
                        expandedDirectories.append(subDir2.absoluteFilePath(subSubDir));
                    }
                }
            }
            // Plus das Hauptverzeichnis f√ºr direkte Dateien
            expandedDirectories.append(directory);
        } else {
            // Kleine Verzeichnisse: Normal behandeln
            expandedDirectories.append(directory);
        }
    }
    
    std::cout << "[Scanner] üöÄ SEQUENTIAL-MODE begrenzt: " << localDirectories.size() 
              << " ‚Üí " << qMin(expandedDirectories.size(), 8) << " Verzeichnisse (sequenziell)" << std::endl;
    
    // SEQUENZIELLE Verarbeitung statt paralleler Threads
    for (int i = 0; i < qMin(expandedDirectories.size(), 8); ++i) {
        const QString &directory = expandedDirectories[i];
        QSet<QString> localProcessedFiles;
        collectDirectoryWorker(directory, localProcessedFiles);
        
        // Kurze Pause zwischen Verzeichnissen f√ºr Stabilit√§t
        QThread::msleep(10);
    }
    
    // Direkter Aufruf der Callback-Funktion
    QTimer::singleShot(100, this, &Scanner::onCollectionFinished);
}

// üßµ Worker-Funktion f√ºr SEQUENZIELLE Dateisammlung (No Threads)
void Scanner::collectDirectoryWorker(const QString &directory, QSet<QString> &processedFiles)
{
    std::cout << "[Scanner] üìÅ SEQUENTIAL-MODE Worker f√ºr: " << directory.toStdString() << std::endl;
    
    if (!scanning.load()) return;
    
    QDir dir(directory);
    if (!dir.exists()) {
        std::cout << "[Scanner] ‚ùå Verzeichnis existiert nicht: " << directory.toStdString() << std::endl;
        return;
    }
    
    // SEQUENTIAL-MODE: Direkter QDirIterator statt QProcess
    QStringList nameFilters = {"*.jpg", "*.jpeg", "*.png", "*.gif", "*.bmp", "*.tiff", "*.webp",
                              "*.mp4", "*.avi", "*.mkv", "*.mov", "*.wmv", "*.flv", "*.webm",
                              "*.mp3", "*.wav", "*.flac", "*.aac", "*.ogg", "*.wma",
                              "*.pdf", "*.doc", "*.docx", "*.txt", "*.rtf", "*.odt",
                              "*.zip", "*.rar", "*.7z", "*.tar", "*.gz", "*.bz2"};
    
    QDirIterator iterator(directory, nameFilters, QDir::Files | QDir::NoSymLinks, 
                         QDirIterator::Subdirectories);
    
    QList<FileInfo> localFiles;
    int fileCount = 0;
    
    while (iterator.hasNext() && scanning.load()) {
        QString filePath = iterator.next();
        QFileInfo fileInfo(filePath);
        
        if (fileInfo.size() == 0) continue;  // Skip empty files
        
        // Thread-safe duplicate check
        QString canonicalPath = getCanonicalPath(filePath);
        if (processedFiles.contains(canonicalPath)) continue;
        processedFiles.insert(canonicalPath);
        
        // Filter anwenden
        if (!currentFileFilter.isEmpty() && 
            currentFileFilter != "*" && 
            !filePath.contains(currentFileFilter, Qt::CaseInsensitive)) {
            continue;
        }
        
        FileInfo info;
        info.filePath = filePath;
        info.fileName = fileInfo.fileName();
        info.size = fileInfo.size();
        info.lastModified = fileInfo.lastModified().toSecsSinceEpoch();
        info.isLocal = true;
        info.networkType = "";
        
        localFiles.append(info);
        fileCount++;
        
        // Status-Update alle 100 Dateien
        if (fileCount % 100 == 0) {
            std::cout << "[Scanner] üìä SEQUENTIAL: " << fileCount << " Dateien gesammelt..." << std::endl;
            QThread::usleep(1000); // 1ms Pause f√ºr Stabilit√§t
        }
    }
    
    // Thread-safe Hinzuf√ºgung aller gefundenen Dateien
    QMutexLocker locker(&filesMutex);
    for (const FileInfo &info : localFiles) {
        allFiles.append(info);
    }
    
    std::cout << "[Scanner] ‚úÖ SEQUENTIAL abgeschlossen: " << fileCount << " Dateien in " 
              << directory.toStdString() << std::endl;
}

// Callback f√ºr abgeschlossene Collection
void Scanner::onCollectionFinished()
{
    std::cout << "[Scanner] ‚úÖ SEQUENTIAL-MODE abgeschlossen: " << allFiles.size() << " Dateien gesammelt" << std::endl;
    emit scanStatusChanged(QString("‚úÖ SEQUENTIAL-MODE: %1 Dateien sicher gesammelt").arg(allFiles.size()));
    
    currentPhase = SIZE_FILTERING;
    emit scanPhaseCompleted(COLLECTING);
    
    // Starte Hash-Processing Pipeline f√ºr gesammelte Dateien
    if (allFiles.isEmpty()) {
        qWarning() << "[Scanner] ‚ö†Ô∏è Keine Dateien gefunden - kann keine Hashes berechnen";
        emit scanCompleted(DuplicateGroups());
        return;
    }
    
    qDebug() << "[Scanner] üéØ Starte Hash-Processing Pipeline f√ºr" << allFiles.size() << "Dateien";
    
    // CONTROLLED Parallel Processing f√ºr 3-Phasen Progress
    int chunkSize = 20;
    int totalFiles = allFiles.size();
    int maxEngines = 4; // Moderate f√ºr Progress-Tracking
    int numParallelEngines = qMin(maxEngines, (totalFiles / chunkSize) + 1);
    
    qDebug() << "[Scanner] üìä 3-Phasen Processing:" << numParallelEngines 
             << "Engines f√ºr" << totalFiles << "Dateien";
    
    activeEngines = numParallelEngines;
    currentFileIndex = 0;
    
    for (int i = 0; i < numParallelEngines; i++) {
        int startIndex = i * chunkSize;
        int endIndex = qMin(startIndex + chunkSize, totalFiles);
        
        if (startIndex < totalFiles) {
            QList<FileInfo> chunk = allFiles.mid(startIndex, endIndex - startIndex);
            
            // Zeitversetzter Start f√ºr Progress-Updates
            int delay = i * 100; // 100ms zwischen Engines
            QTimer::singleShot(delay, this, [this, chunk, i]() {
                processFileChunkParallel(chunk, i);
            });
            
            qDebug() << "[Scanner] üöÄ Engine" << (i+1) << "‚Üí" << chunk.size() 
                     << "Dateien (Delay:" << delay << "ms)";
        }
    }
}

bool Scanner::isScanning() const { return scanning.load(); }
bool Scanner::isPaused() const { return paused.load(); }

// üåê Test FTP Connection Limit (Progressive Testing)
int Scanner::testFtpConnectionLimit(const QString &host, int port, const QString &user, const QString &pass)
{
    std::cout << "[Scanner] üß™ Teste FTP Connection Limit f√ºr " << host.toStdString() << std::endl;
    
    QList<FtpClient*> testClients;
    int maxConnections = 1;
    
    // Progressive Testing: 1, 2, 4, 8, 16, 32 Verbindungen testen
    QList<int> testLimits = {1, 2, 4, 8, 16, 32};
    
    for (int testLimit : testLimits) {
        bool allConnected = true;
        
        std::cout << "[Scanner] üß™ Teste " << testLimit << " parallele Verbindungen..." << std::endl;
        
        // Erstelle Test-Clients
        for (int i = testClients.size(); i < testLimit; i++) {
            FtpClient *testClient = new FtpClient(this);
            testClient->setCredentials(host, port, user, pass);
            testClients.append(testClient);
        }
        
        // Teste alle Verbindungen parallel
        for (int i = 0; i < testLimit; i++) {
            bool connected = false;
            
            // Synchroner Verbindungstest (vereinfacht)
            QEventLoop loop;
            QTimer timeout;
            timeout.setSingleShot(true);
            timeout.setInterval(2000); // 2 Sekunden Timeout
            
            connect(testClients[i], &FtpClient::connected, &loop, [&loop, &connected]() {
                connected = true;
                loop.quit();
            });
            connect(testClients[i], &FtpClient::error, &loop, [&loop, &connected](const QString &) {
                connected = false;
                loop.quit();
            });
            connect(&timeout, &QTimer::timeout, &loop, [&loop, &connected]() {
                connected = false;
                loop.quit();
            });
            
            testClients[i]->connectToHost();
            timeout.start();
            loop.exec();
            
            if (!connected) {
                allConnected = false;
            }
            
            std::cout << "[Scanner] üß™ Verbindung " << (i+1) << "/" << testLimit 
                      << ": " << (connected ? "‚úÖ OK" : "‚ùå FAIL") << std::endl;
        }
        
        if (allConnected) {
            maxConnections = testLimit;
            std::cout << "[Scanner] ‚úÖ " << testLimit << " parallele Verbindungen erfolgreich!" << std::endl;
        } else {
            std::cout << "[Scanner] ‚ùå " << testLimit << " Verbindungen zu viele - Limit bei " 
                      << maxConnections << std::endl;
            break;
        }
        
        // Kleine Pause zwischen Tests
        QThread::msleep(500);
    }
    
    // Cleanup Test-Clients
    for (FtpClient *client : testClients) {
        client->deleteLater();
    }
    testClients.clear();
    
    std::cout << "[Scanner] üåê FTP Connection Limit ermittelt: " << maxConnections 
              << " parallele Verbindungen" << std::endl;
    
    return maxConnections;
}

// üåê Multi-Connection FTP Directory Collection
void Scanner::collectFtpDirectoryMultiConnection(const QString &ftpDirectory)
{
    std::cout << "[Scanner] üöÄüåê MULTI-CONNECTION FTP-Sammlung f√ºr: " << ftpDirectory.toStdString() << std::endl;
    
    QUrl ftpUrl(ftpDirectory);
    QString host = ftpUrl.host();
    int port = ftpUrl.port(21);
    
    LoginData login = presetManager->getLogin(host, port);
    if (!login.isValid()) return;
    
    // üåê Setup Connection Pool
    setupFtpConnectionPool(host, port, login.username, login.password, maxFtpConnections);
    
    // üöÄ MEGA-PARALLEL: Erstelle File-Lists via Multi-Connection
    std::cout << "[Scanner] üöÄ Nutze " << (ftpConnectionPools.contains(host) ? ftpConnectionPools[host].size() : 0)
              << " parallele FTP-Verbindungen f√ºr chunks" << std::endl;
    
    // Hole alle Files √ºber erste Verbindung (Directory Listing)
    QSet<QString> processedFiles;
    collectFtpFiles(ftpDirectory, processedFiles);
    
    std::cout << "[Scanner] ‚úÖ Multi-Connection FTP-Sammlung abgeschlossen: " 
              << processedFiles.size() << " Dateien" << std::endl;
}

// üåê Setup FTP Connection Pool
void Scanner::setupFtpConnectionPool(const QString &host, int port, const QString &user, const QString &pass, int maxConnections)
{
    std::cout << "[Scanner] üèóÔ∏è Erstelle FTP Connection Pool f√ºr " << host.toStdString() << ": " << maxConnections << " Verbindungen" << std::endl;
    
    QMutexLocker locker(&ftpPoolsMutex);
    
    // Cleanup existing pool for this host
    if (ftpConnectionPools.contains(host)) {
        for (FtpClient *client : ftpConnectionPools[host]) {
            client->deleteLater();
        }
        ftpConnectionPools[host].clear();
    }
    
    // Store current connection info
    currentFtpHost = host;
    currentFtpPort = port;
    currentFtpUser = user;
    currentFtpPass = pass;
    this->maxFtpConnections = maxConnections;
    currentFtpConnectionIndex = 0;
    
    // Create connection pool for this host
    QList<FtpClient*> hostPool;
    for (int i = 0; i < maxConnections; i++) {
        FtpClient *client = new FtpClient(this);
        client->setCredentials(host, port, user, pass);
        
        // Pre-connect all clients
        client->connectToHost();
        
        hostPool.append(client);
        
        std::cout << "[Scanner] üîó FTP-Client " << (i+1) << "/" << maxConnections 
                  << " erstellt f√ºr " << host.toStdString() << std::endl;
    }
    
    ftpConnectionPools[host] = hostPool;
    
    std::cout << "[Scanner] ‚úÖ FTP Connection Pool erstellt: " << hostPool.size() 
              << " parallele Verbindungen ready" << std::endl;
}

// üöÄ RADICAL PARALLEL: Multi-Hash-Engine FTP Processing
void Scanner::collectFtpDirectoryRadicalParallel(const QString &ftpDirectory)
{
    std::cout << "[Scanner] ÔøΩÔ∏è SAFE PARALLEL FTP-Sammlung f√ºr: " << ftpDirectory.toStdString() << std::endl;
    
    QUrl ftpUrl(ftpDirectory);
    QString host = ftpUrl.host();
    int port = ftpUrl.port(21);
    
    if (!presetManager) {
        qCritical() << "[Scanner] ‚ùå PresetManager nicht verf√ºgbar f√ºr RADICAL PARALLEL";
        return;
    }
    
    LoginData login = presetManager->getLogin(host, port);
    if (!login.isValid()) {
        qWarning() << "[Scanner] ‚ö†Ô∏è Keine Login-Daten f√ºr RADICAL PARALLEL:" << host;
        return;
    }
    
    // üåê STEP 1: Ultra-Fast Connection Test (reduced timeout)
    int maxConnections = testFtpConnectionLimitFast(host, port, login.username, login.password);
    std::cout << "[Scanner] üåê RADICAL: FTP-Server " << host.toStdString() 
              << " unterst√ºtzt " << maxConnections << " parallele Verbindungen" << std::endl;
    
    // üöÄ STEP 2: Create SAFE PARALLEL Hash-Processing
    if (maxConnections > 1) {
        setupFtpConnectionPool(host, port, login.username, login.password, maxConnections);
        
        // ÔøΩÔ∏è MEMORY SAFETY: Use only 1 Hash Engine to prevent hardware detection conflicts
        std::cout << "[Scanner] üõ°Ô∏è SAFE: Erstelle 1 Hash-Engine f√ºr stabilen FTP-Betrieb" << std::endl;
        
        try {
            HashEngine *safeHashEngine = new HashEngine(this);
            connect(safeHashEngine, &HashEngine::hashCalculated, 
                    this, &Scanner::onHashCalculated);
            
            std::cout << "[Scanner] ‚úÖ SAFE: Hash-Engine erstellt f√ºr FTP-Verarbeitung" << std::endl;
            
            // üöÄ STEP 3: Start SAFE file processing with single engine
            QTimer::singleShot(100, this, [this, ftpDirectory]() {
                startRadicalParallelProcessing(QStringList{ftpDirectory});
            });
        } catch (const std::exception &e) {
            qCritical() << "[Scanner] ‚ùå SAFE: Hash-Engine creation failed:" << e.what();
            // Fallback to normal processing
            QSet<QString> processedFiles;
            collectFtpFiles(ftpDirectory, processedFiles);
        } catch (...) {
            qCritical() << "[Scanner] ‚ùå SAFE: Unknown error during Hash-Engine creation";
            // Fallback to normal processing  
            QSet<QString> processedFiles;
            collectFtpFiles(ftpDirectory, processedFiles);
        }
    } else {
        // Fallback to normal processing
        QSet<QString> processedFiles;
        collectFtpFiles(ftpDirectory, processedFiles);
    }
}

// SIMPLIFIED VERSION
void Scanner::collectFtpDirectoryRadicalParallelSimple(const QString &ftpDirectory)
{
    std::cout << "[Scanner] üì° SIMPLIFIED FTP-Sammlung f√ºr: " << ftpDirectory.toStdString() << std::endl;
    QSet<QString> processedFiles;
    collectFtpFiles(ftpDirectory, processedFiles);
    std::cout << "[Scanner] ‚úÖ FTP-Sammlung abgeschlossen: " << allFiles.size() << " Dateien" << std::endl;
}

// üõ°Ô∏è SAFE FTP Connection Limit Test - NO QEventLoop to prevent memory corruption
int Scanner::testFtpConnectionLimitFast(const QString &host, int port, const QString &user, const QString &pass)
{
    std::cout << "[Scanner] ‚ö° SAFE Connection Limit Test f√ºr " << host.toStdString() << std::endl;
    
    // üõ°Ô∏è SAFETY FIRST: Use direct libcurl testing instead of Qt event loops
    int maxConnections = 1; // Default safe fallback
    
    // üöÄ Direct libcurl testing - NO Qt objects that can cause memory corruption
    auto testConnection = [&](int testLimit) -> bool {
        std::cout << "[Scanner] ‚ö° Teste " << testLimit << " parallele Verbindungen (SAFE)..." << std::endl;
        
        std::vector<CURL*> testHandles;
        bool allConnected = true;
        
        for (int i = 0; i < testLimit; i++) {
            CURL* curl = curl_easy_init();
            if (!curl) {
                allConnected = false;
                break;
            }
            
            QString url = QString("ftp://%1:%2/").arg(host).arg(port);
            curl_easy_setopt(curl, CURLOPT_URL, url.toUtf8().constData());
            curl_easy_setopt(curl, CURLOPT_USERNAME, user.toUtf8().constData());
            curl_easy_setopt(curl, CURLOPT_PASSWORD, pass.toUtf8().constData());
            curl_easy_setopt(curl, CURLOPT_TIMEOUT, 3L);  // 3 second timeout
            curl_easy_setopt(curl, CURLOPT_NOBODY, 1L);   // HEAD request only
            curl_easy_setopt(curl, CURLOPT_FTP_USE_EPSV, 1L);
            
            CURLcode res = curl_easy_perform(curl);
            testHandles.push_back(curl);
            
            if (res != CURLE_OK) {
                std::cout << "[Scanner] ‚ùå Connection " << i << " failed: " 
                          << curl_easy_strerror(res) << std::endl;
                allConnected = false;
            }
        }
        
        // Cleanup all handles
        for (CURL* curl : testHandles) {
            curl_easy_cleanup(curl);
        }
        testHandles.clear();
        
        return allConnected;
    };
    
    // Test conservative limits: 1, 2, 4 (reduce aggressiveness)
    QList<int> testLimits = {1, 2, 4};
    
    for (int testLimit : testLimits) {
        if (testConnection(testLimit)) {
            maxConnections = testLimit;
            std::cout << "[Scanner] ‚úÖ SAFE: " << testLimit << " Verbindungen OK!" << std::endl;
        } else {
            std::cout << "[Scanner] ‚ùå SAFE: " << testLimit << " zu viele - Limit: " 
                      << maxConnections << std::endl;
            break;
        }
    }
    
    std::cout << "[Scanner] ‚ö° SAFE Connection Limit: " << maxConnections << std::endl;
    return maxConnections;
}

// üöÄ RADICAL PARALLEL Processing Engine
void Scanner::startRadicalParallelProcessing(const QStringList &ftpDirectories)
{
    for (const QString &ftpDirectory : ftpDirectories) {
        std::cout << "[Scanner] üöÄüöÄüöÄ RADICAL PARALLEL Processing gestartet f√ºr: " 
                  << ftpDirectory.toStdString() << std::endl;
        
        // üöÄ STEP 1: Hole alle Files via FTP-LIST (schnell)
        QSet<QString> processedFiles;
        collectFtpFiles(ftpDirectory, processedFiles);
    }
    
    std::cout << "[Scanner] üöÄ RADICAL: " << allFiles.size() 
              << " Dateien gesammelt - starte MEGA-PARALLEL Hashing" << std::endl;
    
    // üöÄ STEP 2: Controlled Processing - FTP-Server-freundlich
    bool hasFtpFiles = false;
    for (const FileInfo &file : allFiles) {
        if (file.filePath.startsWith("ftp://")) {
            hasFtpFiles = true;
            break;
        }
    }
    
    int totalFiles = allFiles.size();
    
    if (hasFtpFiles) {
        // üöÄ FTP: 8 ENGINES f√ºr maximale Parallelit√§t bei Server-Stabilit√§t
        std::cout << "[Scanner] üì° FTP-Dateien erkannt: 8 ENGINE Verarbeitung f√ºr " 
                  << totalFiles << " Dateien" << std::endl;
        
        // Initialize continuous processing
        currentFileIndex = 0;
        activeEngines = 0;
        
        // üöÄüöÄüöÄ ULTIMATIVE OPTIMIERUNG: HashEngine-Pool f√ºr FTP MEGA-SPEED
        std::cout << "[Scanner] üè≠ Erstelle HashEngine-POOL f√ºr 8 Engines..." << std::endl;
        
        // FTP: Verwende ALLE 8 Engines gleichzeitig f√ºr maximale Performance
        int chunkSize = 20; // 20 Dateien pro Engine f√ºr FTP
        int numEngines = 8; // IMMER 8 Engines f√ºr maximale Parallelit√§t
        
        // ‚ú® ENHANCED POOL: Pre-create and pre-initialize engines to eliminate ALL overhead
        enginePool.clear();
        
        // üåê COLLECT ALL FTP HOSTS from allFiles for comprehensive credential setup
        QSet<QString> ftpHosts;
        for (const FileInfo &file : allFiles) {
            if (file.filePath.startsWith("ftp://")) {
                QUrl url(file.filePath);
                ftpHosts.insert(url.host());
            }
        }
        
        std::cout << "[Scanner] üåê Erkannte FTP-Hosts: " << ftpHosts.size() << " Hosts: " 
                  << QStringList(ftpHosts.values()).join(", ").toStdString() << std::endl;
        
        for (int i = 0; i < 8; i++) {
            HashEngine* poolEngine = new HashEngine();
            
            // üöÄ PRE-INITIALIZE: Set up FTP credentials for ALL detected hosts
            for (const QString &host : ftpHosts) {
                LoginData login = presetManager->getLogin(host, 21);
                if (login.isValid()) {
                    poolEngine->setFtpCredentials(host, login.username, login.password);
                    std::cout << "[Scanner] üîê Engine " << i << " FTP-Credentials vorgesetzt f√ºr " 
                              << host.toStdString() << " (User: " << login.username.toStdString() << ")" << std::endl;
                } else {
                    std::cout << "[Scanner] ‚ö†Ô∏è Engine " << i << " keine Credentials f√ºr " << host.toStdString() << std::endl;
                }
            }
            
            // üöÄ FORCE HARDWARE INITIALIZATION: Avoid lazy loading overhead
            poolEngine->forceHardwareInitialization();
            
            // üßµ SET PARENT for proper signal handling and cleanup
            poolEngine->setParent(this);
            
            enginePool.append(poolEngine);
            std::cout << "[Scanner] üöÄ HashEngine " << i << " f√ºr Pool erstellt & vorinitialisiert (Hosts: " 
                      << ftpHosts.size() << ")" << std::endl;
        }
        
        // üîó Setup FTP Connection Pool f√ºr alle erkannten Hosts
        setupMultiHostFtpConnectionPool(ftpHosts);
        
        std::cout << "[Scanner] üöÄüöÄüöÄ TURBO: " << numEngines 
                  << " Engines GLEICHZEITIG f√ºr " << totalFiles << " Dateien (FTP: JA)" << std::endl;
        
        // üß† INTELLIGENT FILE DISTRIBUTION: Sortiere nach Gr√∂√üe und verteile ausgewogen
        QList<QList<FileInfo>> balancedChunks = createBalancedFileChunks(allFiles, numEngines);
        
        // Starte ALLE 8 Engines gleichzeitig mit ausgewogenen Chunks
        for (int i = 0; i < qMin(numEngines, balancedChunks.size()); i++) {
            if (!balancedChunks[i].isEmpty()) {
                activeEngines++;
                
                // Minimale Delays nur f√ºr FTP-Server-Freundlichkeit
                int delay = i * 25; // Nur 25ms zwischen FTP-Engines
                QTimer::singleShot(delay, this, [this, balancedChunks, i]() {
                    // Verwende HashEngine aus Pool (keine Re-Initialisierung!)
                    if (i < enginePool.size()) {
                        qint64 chunkSizeGB = calculateChunkSize(balancedChunks[i]) / (1024 * 1024 * 1024);
                        std::cout << "[Scanner] üöÄüöÄ BALANCED Engine " << i << " ‚Üí " 
                                  << balancedChunks[i].size() << " Dateien (" 
                                  << chunkSizeGB << " GB)" << std::endl;
                        processFileChunkParallelWithPoolEngine(balancedChunks[i], i, enginePool[i]);
                    } else {
                        qWarning() << "[Scanner] ‚ùå Engine Pool zu klein f√ºr Engine" << i;
                    }
                });
            }
        }
        
        std::cout << "[Scanner] üì° " << activeEngines << " BALANCED FTP-Engines gestartet f√ºr " 
                  << totalFiles << " Dateien" << std::endl;
    } else {
        // üöÄ LOKAL: INTELLIGENT BALANCED PARALLEL f√ºr maximale Geschwindigkeit
        int numParallelEngines = qMin(8, qMax(1, totalFiles / 10)); // MAXIMAL 8 parallel engines, mindestens 1
        
        std::cout << "[Scanner] üöÄ LOKAL BALANCED: Verwende " << numParallelEngines 
                  << " parallele Engines f√ºr " << totalFiles << " Dateien" << std::endl;
        
        // üß† INTELLIGENT FILE DISTRIBUTION auch f√ºr lokale Dateien
        QList<QList<FileInfo>> balancedChunks = createBalancedFileChunks(allFiles, numParallelEngines);
        
        // Starte intelligente parallele Hash-Berechnung
        for (int i = 0; i < qMin(numParallelEngines, balancedChunks.size()); i++) {
            if (!balancedChunks[i].isEmpty()) {
                // Staggered start f√ºr System-Stabilit√§t
                int delay = i * 100; // 100ms zwischen lokalen Engines
                QTimer::singleShot(delay, this, [this, balancedChunks, i]() {
                    qint64 chunkSizeGB = calculateChunkSize(balancedChunks[i]) / (1024 * 1024 * 1024);
                    qint64 chunkSizeMB = (calculateChunkSize(balancedChunks[i]) % (1024 * 1024 * 1024)) / (1024 * 1024);
                    
                    std::cout << "[Scanner] üöÄ LOKAL Engine " << (i+1) << " bearbeitet " 
                              << balancedChunks[i].size() << " Dateien (" 
                              << chunkSizeGB << "." << QString::number(chunkSizeMB).rightJustified(3, '0').toStdString() 
                              << " GB)" << std::endl;
                    
                    processFileChunkParallel(balancedChunks[i], i);
                });
            }
        }
    }
}

// üè≠ POOL-ENGINE PROCESSING: Verwendet pre-initialized HashEngine aus Pool
void Scanner::processFileChunkParallelWithPoolEngine(const QList<FileInfo> &chunk, int engineIndex, HashEngine* poolEngine)
{
    if (!poolEngine) {
        qWarning() << "[Scanner] ‚ùå POOL-ENGINE NULL f√ºr Engine" << engineIndex;
        activeEngines--;
        return;
    }

    std::cout << "[Scanner] üè≠ POOL-Engine " << engineIndex << " startet mit " 
              << chunk.size() << " Dateien (KEINE OpenCL Re-Init!)" << std::endl;

    // Copy FTP credentials from presetManager for all collected FTP hosts
    QStringList currentFtpHosts;
    for (const FileInfo &file : chunk) {
        if (file.filePath.startsWith("ftp://")) {
            QUrl url(file.filePath);
            QString host = url.host();
            if (!currentFtpHosts.contains(host)) {
                currentFtpHosts.append(host);
            }
        }
    }
    
    for (const QString &host : currentFtpHosts) {
        LoginData login = presetManager->getLogin(host, 21);  
        if (login.isValid()) {
            poolEngine->setFtpCredentials(host, login.username, login.password);
            std::cout << "[Scanner] üîê POOL-Engine " << engineIndex << " FTP-Credentials kopiert f√ºr: " << host.toStdString() << std::endl;
        }
    }

    // Process each file in the chunk with pool engine
    for (int i = 0; i < chunk.size(); ++i) {
        const FileInfo &file = chunk[i];
        
        // ‚úÖ EMIT CURRENT FILE PROCESSING f√ºr Real-time UI Update
        QMetaObject::invokeMethod(this, [this, file, i, chunk]() {
            QFileInfo tempInfo(file.filePath);
            emit currentFileProcessing(tempInfo.fileName(), "Hashing", i + 1, chunk.size());
        }, Qt::QueuedConnection);
        
        // Set algorithm and calculate hash
        poolEngine->setAlgorithm(HashEngine::SHA1);
        QString hash = poolEngine->calculateFileHash(file.filePath);
        
        // ‚úÖ KRITISCH: Hash an Scanner f√ºr Duplikat-Vergleich weitergeben
        if (!hash.isEmpty()) {
            QMetaObject::invokeMethod(this, [this, file, hash]() {
                processHashResult(file, hash); // Zentrale Hash-Sammlung f√ºr Duplikat-Erkennung
            }, Qt::QueuedConnection);
        }
        
        // ‚úÖ POOL ENGINE PROGRESS: Verwende echte processedFiles Z√§hlung
        if (i % 10 == 0 || i == chunk.size() - 1) {
            QMetaObject::invokeMethod(this, [this]() {
                // Verwende die echten Zahlen aus Console
                int currentProcessed = processedFilesCounter.load();
                int progress = (currentProcessed * 100) / allFiles.size();
                emit scanProgress(progress, currentProcessed, allFiles.size());
                
                // NPU Activity Update basierend auf echten Zahlen
                int duplicateGroups = 0;
                {
                    QMutexLocker locker(&sharedHashGroupsMutex);
                    for (auto it = sharedHashGroups.begin(); it != sharedHashGroups.end(); ++it) {
                        if (it.value().size() > 1) duplicateGroups++;
                    }
                }
                emit npuActivityUpdate(currentProcessed, duplicateGroups);
            }, Qt::QueuedConnection);
        }
    }

    std::cout << "[Scanner] ‚úÖ POOL-Engine " << engineIndex << " abgeschlossen (POOL-OPTIMIERT)!" << std::endl;
    
    // Continue with next chunk
    QMetaObject::invokeMethod(this, [this, engineIndex]() {
        startNextEngineIfNeeded(engineIndex);
    }, Qt::QueuedConnection);
}

// ‚úÖ ZENTRALE HASH-SAMMLUNG: Sammelt Hashes von Pool Engines f√ºr Duplikat-Erkennung
void Scanner::processHashResult(const FileInfo &fileInfo, const QString &hash)
{
    if (hash.isEmpty()) return;
    
    // Update file with hash
    FileInfo updatedFile = fileInfo;
    updatedFile.hash = hash;
    
    // Thread-safe access to shared hash groups
    {
        QMutexLocker locker(&sharedHashGroupsMutex);
        
        // Add to hash storage for duplicate detection
        if (sharedHashGroups.contains(hash)) {
            // Found duplicate!
            sharedHashGroups[hash].append(updatedFile);
            std::cout << "[Scanner] üî• DUPLIKAT GEFUNDEN! Hash " << hash.left(8).toStdString() 
                      << ": " << sharedHashGroups[hash].size() << " Dateien" << std::endl;
        } else {
            // First occurrence of this hash
            sharedHashGroups[hash].append(updatedFile);
        }
    }
    
    // Atomic increment of processed files counter
    int currentProcessed = processedFilesCounter.fetch_add(1) + 1;
    
    // Check if scan is complete
    if (currentProcessed >= allFiles.size()) {
        QTimer::singleShot(1000, this, [this]() {
            emitDuplicatesFound();
        });
    }
}

// ‚úÖ DUPLIKAT-EMIT: Sende gefundene Duplikate an GUI
void Scanner::emitDuplicatesFound()
{
    QList<DuplicateGroup> duplicateGroups;
    int totalDuplicates = 0;
    
    // Thread-safe access to read final results
    {
        QMutexLocker locker(&sharedHashGroupsMutex);
        
        for (auto it = sharedHashGroups.begin(); it != sharedHashGroups.end(); ++it) {
            const QList<FileInfo> &files = it.value();
            if (files.size() > 1) {
                DuplicateGroup group;
                group.hash = it.key();
                group.original = files.first(); // Keep first as original
                group.duplicates = files.mid(1); // All others are duplicates
                duplicateGroups.append(group);
                totalDuplicates += files.size() - 1; // Duplicates = total - 1 original
            }
        }
    }
    
    std::cout << "[Scanner] üéØ SCANNING ABGESCHLOSSEN: " << duplicateGroups.size() 
              << " Gruppen, " << totalDuplicates << " Duplikate gefunden!" << std::endl;
    
    // Emit signals to GUI
    emit scanStatusChanged(QString("‚úÖ Scan abgeschlossen: %1 Duplikat-Gruppen gefunden")
                          .arg(duplicateGroups.size()));
    emit duplicatesDetected(duplicateGroups);
    emit scanProgress(100, allFiles.size(), allFiles.size());
}

// üöÄ Process file chunk with dedicated hash engine
void Scanner::processFileChunkParallel(const QList<FileInfo> &chunk, int engineIndex)
{
    std::cout << "[Scanner] üöÄ Engine " << engineIndex << " startet mit " 
              << chunk.size() << " Dateien (SEPARATE HASHENGINE!)" << std::endl;
    
    // üöÄ SEPARATE HASHENGINE: Jede Engine bekommt ihre eigene HashEngine-Instanz
    HashEngine* dedicatedEngine = new HashEngine(this);
    dedicatedEngine->setAlgorithm(HashEngine::SHA1); // Default algorithm
    
    // Copy FTP credentials from presetManager for all collected FTP hosts
    QStringList currentFtpHosts;
    for (const FileInfo &file : chunk) {
        if (file.filePath.startsWith("ftp://")) {
            QUrl url(file.filePath);
            QString host = url.host();
            if (!currentFtpHosts.contains(host)) {
                currentFtpHosts.append(host);
            }
        }
    }
    
    for (const QString &host : currentFtpHosts) {
        LoginData login = presetManager->getLogin(host, 21);  
        if (login.isValid()) {
            dedicatedEngine->setFtpCredentials(host, login.username, login.password);
            std::cout << "[Scanner] üîê Engine " << engineIndex << " FTP-Credentials kopiert f√ºr: " << host.toStdString() << std::endl;
        }
    }
    
    std::cout << "[Scanner] üîß Engine " << engineIndex << " mit separater HashEngine initialisiert" << std::endl;
    
    // üöÄ PARALLEL PROCESSING: Process files in sequence within chunk
    int filesProcessedInChunk = 0;
    for (const FileInfo &fileInfo : chunk) {
        if (!scanning.load()) break;
        
        // ‚úÖ EMIT CURRENT FILE PROCESSING f√ºr Real-time UI Update
        QMetaObject::invokeMethod(this, [this, fileInfo, filesProcessedInChunk, chunk]() {
            QFileInfo tempInfo(fileInfo.filePath);
            emit currentFileProcessing(tempInfo.fileName(), "Parallel Hashing", filesProcessedInChunk + 1, chunk.size());
        }, Qt::QueuedConnection);
        
        // Use dedicated HashEngine for thread safety
        QString hash = dedicatedEngine->calculateFileHash(fileInfo.filePath);
        if (!hash.isEmpty()) {
            // Thread-safe hash result handling
            QMetaObject::invokeMethod(this, [this, fileInfo, hash]() {
                onHashCalculated(fileInfo.filePath, hash);
            }, Qt::QueuedConnection);
        }
        
        filesProcessedInChunk++;
        
        // üìä GUI PROGRESS UPDATE: Nur alle 10 Dateien f√ºr Performance
        if (filesProcessedInChunk % 10 == 0) {
            // ‚úÖ CRITICAL FIX: Erh√∂he globalen processedFiles Counter
            int totalProcessed = processedFilesCounter.fetch_add(1) + 1;
            int progressPercent = (totalProcessed * 100) / qMax(1, allFiles.size());
            
            QMetaObject::invokeMethod(this, [this, progressPercent, totalProcessed]() {
                emit scanProgress(progressPercent, totalProcessed, allFiles.size());
                emit scanStatusChanged(QString("üîê Hash-Berechnung: Engine %1/%2 ‚Üí %3/%4 (%5%)")
                                       .arg(activeEngines).arg(maxEngines)
                                       .arg(totalProcessed).arg(allFiles.size())
                                       .arg(progressPercent));
                
                // ‚úÖ COMPLETION CHECK: Wenn alle Dateien verarbeitet wurden
                if (totalProcessed >= allFiles.size()) {
                    QTimer::singleShot(100, this, [this]() {
                        emitDuplicatesFound();
                    });
                }
            }, Qt::QueuedConnection);
        }
        
        // TURBO: Keine Delays f√ºr maximale Geschwindigkeit
        // QThread::msleep(10); // ENTFERNT f√ºr maximale Performance
    }
    
    // Cleanup separate engine
    dedicatedEngine->deleteLater();
    
    std::cout << "[Scanner] ‚úÖ Engine " << engineIndex << " abgeschlossen (SEPARATE HASHENGINE)!" << std::endl;
    
    // ‚úÖ ENGINE COMPLETION: Final progress check f√ºr diese Engine
    int totalProcessed = processedFilesCounter.load();
    int progressPercent = (totalProcessed * 100) / qMax(1, allFiles.size());
    
    QMetaObject::invokeMethod(this, [this, progressPercent, totalProcessed, engineIndex]() {
        emit scanProgress(progressPercent, totalProcessed, allFiles.size());
        emit scanStatusChanged(QString("‚úÖ Hash-Engine %1/%2 beendet: %3/%4 (%5%)")
                               .arg(engineIndex).arg(maxEngines)
                               .arg(totalProcessed).arg(allFiles.size())
                               .arg(progressPercent));
        
        // ‚úÖ FINAL COMPLETION CHECK: Wenn alle Dateien verarbeitet wurden
        if (totalProcessed >= allFiles.size()) {
            QTimer::singleShot(50, this, [this]() {
                emitDuplicatesFound();
            });
        } else {
            // üöÄ CONTINUOUS PROCESSING: Starte n√§chste Engine falls noch Dateien vorhanden
            startNextEngineIfNeeded(engineIndex);
        }
    }, Qt::QueuedConnection);
}

// ‚õî ENGINE STOPPER: Stops all processing engines immediately on login errors
void Scanner::stopAllEngines()
{
    std::cout << "[Scanner] ‚õî EMERGENCY STOP: Alle Engines werden gestoppt!" << std::endl;
    
    // Stop main scanning immediately
    scanning.store(false);
    
    // Signal to stop all processing
    emit scanStatusChanged("‚õî Angehalten: Login-Fehler erkannt");
    emit error("FTP Login-Fehler: Scanner gestoppt. Bitte Login-Daten pr√ºfen.");
    
    std::cout << "[Scanner] ‚õî Alle Engines gestoppt!" << std::endl;
}

// üöÄ CONTINUOUS ENGINE MANAGEMENT: Startet n√§chste Engine falls noch Dateien vorhanden
void Scanner::startNextEngineIfNeeded(int completedEngineIndex)
{
    // Decrement active engine count
    activeEngines--;
    
    std::cout << "[Scanner] üîÑ Engine " << completedEngineIndex << " beendet. Aktive Engines: " 
              << activeEngines << "/" << maxEngines << std::endl;
    
    // Check if we have more files to process
    if (currentFileIndex < allFiles.size() && scanning.load()) {
        // Calculate next chunk
        int remainingFiles = allFiles.size() - currentFileIndex;
        int chunkSize = qMin(engineChunkSize, remainingFiles);
        
        if (chunkSize > 0) {
            // Get next chunk of files
            QList<FileInfo> nextChunk = allFiles.mid(currentFileIndex, chunkSize);
            currentFileIndex += chunkSize;
            activeEngines++;
            
            std::cout << "[Scanner] üöÄ CONTINUOUS: Starte Engine " << completedEngineIndex 
                      << " neu mit " << chunkSize << " Dateien (Index: " 
                      << (currentFileIndex - chunkSize) << "-" << (currentFileIndex - 1) 
                      << "/" << allFiles.size() << ")" << std::endl;
            
            // Start next engine IMMEDIATELY for maximum speed
            processFileChunkParallel(nextChunk, completedEngineIndex);
        } else {
            std::cout << "[Scanner] ‚úÖ Keine weiteren Dateien f√ºr Engine " << completedEngineIndex << std::endl;
        }
    } else {
        std::cout << "[Scanner] ‚úÖ Engine " << completedEngineIndex << " beendet - keine weiteren Dateien" << std::endl;
    }
    
    // Check if all engines are finished
    if (activeEngines == 0 && currentFileIndex >= allFiles.size()) {
        std::cout << "[Scanner] üéâ ALLE ENGINES ABGESCHLOSSEN! " << allFiles.size() << " Dateien verarbeitet!" << std::endl;
        
        // Start final comparison phase
        QTimer::singleShot(500, this, [this]() {
            compareHashes();
        });
    }
}

// üîß NEUE SLOT-METHODE: Kompatibel mit FtpClient::listFinished Signal
void Scanner::onFtpListFinished(const QStringList &allDirs, bool success)
{
    qDebug() << "[Scanner] üì° FTP-List empfangen:" << allDirs.size() << "Verzeichnisse, Success:" << success;
    
    if (success && !allDirs.isEmpty()) {
        // Konvertiere allDirs zu Dateien f√ºr weitere Verarbeitung
        for (const QString &dir : allDirs) {
            qDebug() << "   üìÇ FTP-Verzeichnis:" << dir;
            // Hier k√∂nnten weitere FTP-Datei-Operationen folgen
        }
    } else {
        qDebug() << "‚ö†Ô∏è FTP-List fehlgeschlagen oder leer";
    }
}

// üåê MULTI-HOST FTP CONNECTION POOL MANAGEMENT
void Scanner::setupMultiHostFtpConnectionPool(const QSet<QString> &ftpHosts)
{
    std::cout << "[Scanner] üèóÔ∏è Erstelle Multi-Host FTP Connection Pools f√ºr " 
              << ftpHosts.size() << " Hosts..." << std::endl;
    
    QMutexLocker locker(&ftpPoolsMutex);
    
    // Cleanup existing pools
    for (auto hostIt = ftpConnectionPools.begin(); hostIt != ftpConnectionPools.end(); ++hostIt) {
        for (FtpClient *client : hostIt.value()) {
            client->deleteLater();
        }
    }
    ftpConnectionPools.clear();
    
    maxConnectionsPerHost = 2; // 2 connections per host for 8 engines
    
    for (const QString &host : ftpHosts) {
        QList<FtpClient*> hostPool;
        
        LoginData login = presetManager->getLogin(host, 21);
        if (!login.isValid()) {
            std::cout << "[Scanner] ‚ùå Keine g√ºltigen Credentials f√ºr Host: " 
                      << host.toStdString() << " - √ºberspringe Pool-Erstellung" << std::endl;
            continue;
        }
        
        // Create multiple connections per host
        for (int i = 0; i < maxConnectionsPerHost; i++) {
            FtpClient *client = new FtpClient(this);
            client->setCredentials(host, 21, login.username, login.password);
            
            // Pre-connect for immediate availability
            client->connectToHost();
            
            hostPool.append(client);
            
            std::cout << "[Scanner] üîó FTP-Client " << (i+1) << "/" << maxConnectionsPerHost 
                      << " erstellt f√ºr " << host.toStdString() 
                      << " (User: " << login.username.toStdString() << ")" << std::endl;
        }
        
        ftpConnectionPools[host] = hostPool;
        std::cout << "[Scanner] ‚úÖ FTP Pool f√ºr " << host.toStdString() 
                  << " erstellt: " << hostPool.size() << " Verbindungen" << std::endl;
    }
    
    std::cout << "[Scanner] üöÄ Multi-Host FTP Connection Pools komplett: " 
              << ftpConnectionPools.size() << " Hosts mit je " 
              << maxConnectionsPerHost << " Verbindungen" << std::endl;
}

FtpClient* Scanner::getFtpClientForHost(const QString &host)
{
    QMutexLocker locker(&ftpPoolsMutex);
    
    if (!ftpConnectionPools.contains(host)) {
        std::cout << "[Scanner] ‚ùå Kein FTP Pool f√ºr Host: " << host.toStdString() << std::endl;
        return nullptr;
    }
    
    QList<FtpClient*> &hostPool = ftpConnectionPools[host];
    if (hostPool.isEmpty()) {
        std::cout << "[Scanner] ‚ö†Ô∏è FTP Pool f√ºr " << host.toStdString() << " ist leer" << std::endl;
        return nullptr;
    }
    
    // Get first available client (simple round-robin)
    FtpClient *client = hostPool.takeFirst();
    std::cout << "[Scanner] üì§ FTP Client f√ºr " << host.toStdString() 
              << " ausgeliehen (Pool: " << hostPool.size() << " verbleibend)" << std::endl;
    
    return client;
}

void Scanner::returnFtpClientToPool(const QString &host, FtpClient *client)
{
    if (!client) return;
    
    QMutexLocker locker(&ftpPoolsMutex);
    
    if (!ftpConnectionPools.contains(host)) {
        std::cout << "[Scanner] ‚ùå Kein Pool f√ºr Host: " << host.toStdString() << " - Client wird gel√∂scht" << std::endl;
        client->deleteLater();
        return;
    }
    
    ftpConnectionPools[host].append(client);
    std::cout << "[Scanner] üì• FTP Client f√ºr " << host.toStdString() 
              << " zur√ºckgegeben (Pool: " << ftpConnectionPools[host].size() << ")" << std::endl;
}

void Scanner::cleanupFtpConnectionPools()
{
    std::cout << "[Scanner] üßπ Cleanup FTP Connection Pools..." << std::endl;
    
    QMutexLocker locker(&ftpPoolsMutex);
    
    for (auto hostIt = ftpConnectionPools.begin(); hostIt != ftpConnectionPools.end(); ++hostIt) {
        for (FtpClient *client : hostIt.value()) {
            client->deleteLater();
        }
        std::cout << "[Scanner] üóëÔ∏è " << hostIt.value().size() << " FTP Clients f√ºr " 
                  << hostIt.key().toStdString() << " gel√∂scht" << std::endl;
    }
    
    ftpConnectionPools.clear();
    std::cout << "[Scanner] ‚úÖ FTP Connection Pools cleanup abgeschlossen" << std::endl;
}

// üß† INTELLIGENT FILE DISTRIBUTION: Sortiert Files nach Gr√∂√üe und erstellt ausgewogene Chunks
QList<QList<FileInfo>> Scanner::createBalancedFileChunks(const QList<FileInfo> &files, int numEngines)
{
    std::cout << "[Scanner] üß† Erstelle ausgewogene File-Chunks f√ºr " << files.size() 
              << " Dateien auf " << numEngines << " Engines..." << std::endl;
    
    QList<FileInfo> sortedFiles = files;
    sortFilesBySize(sortedFiles);
    
    // Erstelle Engine-Chunks mit Gr√∂√üen-Tracking
    QList<QList<FileInfo>> chunks(numEngines);
    QList<qint64> chunkSizes(numEngines, 0);
    
    // Round-Robin Distribution der gr√∂√üten Dateien zuerst
    for (int i = 0; i < sortedFiles.size(); i++) {
        // Finde Engine mit kleinster aktueller Last
        int bestEngine = 0;
        qint64 minSize = chunkSizes[0];
        
        for (int j = 1; j < numEngines; j++) {
            if (chunkSizes[j] < minSize) {
                minSize = chunkSizes[j];
                bestEngine = j;
            }
        }
        
        // F√ºge Datei zur Engine mit geringster Last hinzu
        chunks[bestEngine].append(sortedFiles[i]);
        chunkSizes[bestEngine] += sortedFiles[i].size;
    }
    
    // Report balancing results
    for (int i = 0; i < numEngines; i++) {
        qint64 sizeGB = chunkSizes[i] / (1024 * 1024 * 1024);
        qint64 sizeMB = (chunkSizes[i] % (1024 * 1024 * 1024)) / (1024 * 1024);
        
        std::cout << "[Scanner] üìä Engine " << i << ": " << chunks[i].size() 
                  << " Dateien, " << sizeGB << "." 
                  << QString::number(sizeMB).rightJustified(3, '0').toStdString() << " GB" << std::endl;
    }
    
    return chunks;
}

void Scanner::sortFilesBySize(QList<FileInfo> &files)
{
    std::sort(files.begin(), files.end(), [](const FileInfo &a, const FileInfo &b) {
        // Sortiere ABSTEIGEND: gr√∂√üte Dateien zuerst f√ºr bessere Lastverteilung
        return a.size > b.size;
    });
    
    if (!files.isEmpty()) {
        qint64 largestGB = files.first().size / (1024 * 1024 * 1024);
        qint64 smallestKB = files.last().size / 1024;
        std::cout << "[Scanner] üìè Dateien sortiert: Gr√∂√üte: " << largestGB 
                  << " GB, Kleinste: " << smallestKB << " KB" << std::endl;
    }
}

qint64 Scanner::calculateChunkSize(const QList<FileInfo> &chunk)
{
    qint64 totalSize = 0;
    for (const FileInfo &file : chunk) {
        totalSize += file.size;
    }
    return totalSize;
}
